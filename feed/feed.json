{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "Jacob&#39;s blog",
  "language": "en",
  "home_page_url": "https://jacobsherin.com/",
  "feed_url": "https://example.com/feed/feed.json",
  "description": "On database building blocks.",
  "author": {
    "name": "Your Name Here",
    "url": "https://example.com/about-me/"
  },
  "items": [{
      "id": "https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/",
      "url": "https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/",
      "title": "Cache-Friendly B+Tree Nodes With Dynamic Fanout",
      "content_html": "<p>For a high-performance B+Tree, the memory layout of each node must be a single contiguous block. This improves locality of reference, increasing the likelihood that the node's contents reside in the CPU cache.</p>\n<p>In C++, achieving this means forgoing the use of <code>std::vector</code>, as it introduces a layer of indirection through a separate memory allocation. The solution to this problem though inevitably increases the implementation complexity and is mired with hidden drawbacks. Nevertheless, this is still a necessary trade-off for unlocking high performance.</p>\n<pre class=\"language-text\"><code class=\"language-text\">  +----------------------+<br />  | Node Metadata Header |<br />  +----------------------+<br />  | node_type_           |<-- Inner Node or Leaf Node<br />  | max_size_            |<-- Maximum Capacity (aka Node Fanout)<br />  | node_latch_          |<-- RW-Lock Mutex<br />  | iter_end_            |--------------------+<br />  +----------------------+                    |<br />  | Node Data            |                    |<br />  +----------------------+                    |<br />  | entries_[0]          | <--+               |<br />  | entries_[1]          |    |               |<br />  | entries_[2]          |    + used space    |<br />  | ...                  |    |               |<br />  | entries_[k]          | <--+               |<br />  +----------------------+<-------------------+ iter_end_ points to<br />  |                      |    entries_[k+1], which is one-past-the-last<br />  | (unused space)       |    entry in the node.<br />  | ...                  |<br />  +----------------------+</code></pre>\n<figcaption>Fig 1. Memory Layout of a B+Tree Node as a single contiguous block in heap</figcaption>\n<nav class=\"toc\" aria-labelledby=\"toc-heading\">\n  <h2 id=\"toc-heading\">Table of Contents</h2>\n  <ol>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#challenges\">Challenges</a></li>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#the-struct-hack\">The Struct Hack</a></li>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#b+tree-node-declaration\">B+Tree Node Declaration</a></li>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#raw-memory-buffer\">Raw Memory Buffer</a></li>\n    <li>\n      <a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#the-price-of-fine-grained-control\">The Price Of Fine-Grained Control</a>\n      <ul>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#manual-handling-of-deallocation\">Manual Handling Of Deallocation</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#adding-new-members-in-a-derived-class\">Adding New Members In A Derived Class</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#reinventing-the-wheel\">Reinventing The Wheel</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#hidden-data-type-assumptions\">Hidden Data Type Assumptions</a></li>\n      </ul>\n    </li>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#conclusion\">Conclusion</a></li>\n  </ol>\n</nav>\n<h2 id=\"challenges\" tabindex=\"-1\">Challenges <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#challenges\" aria-hidden=\"true\">#</a></h2>\n<p>Using <code>std::vector</code> for a B+Tree node's entries is a non-starter. A <code>std::vector</code> object holds a pointer to its entries which are stored in a separate block of memory on the heap. This indirection fragments the memory layout, forcing us to fall back on C-style arrays for a contiguous layout when storing variable-length node entries.</p>\n<p>This leads to a dilemma. The size of the array must be known at compilation time, yet we need to allow users to configure the fanout (the array's size) at runtime. Furthermore, the implementation should allow inner nodes and leaf nodes to have different fanouts.</p>\n<p>This isn't just a B+Tree problem. It is a common challenge in systems programming whenever an object needs to contain a variable-length payload whose size is only known at runtime. How can you define a class that occupies a single block of memory when a part of the block has a dynamic size?</p>\n<p>The solution isn't obvious, but it's a well-known trick that systems programmers have used for decades, a technique so common it has eventually been standardized in C99.</p>\n<h2 id=\"the-struct-hack\" tabindex=\"-1\">The Struct Hack <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#the-struct-hack\" aria-hidden=\"true\">#</a></h2>\n<p>The solution to this problem is a technique originating in C programming known as the struct hack. The variable-length member (array) is placed at the last position in the struct. To satisfy the compiler an array size of one is hard-coded, ensuring the array size is known at compilation time.</p>\n<pre class=\"language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> <span class=\"token class-name\">Payload</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token comment\">/* Header Section */</span><br />  <span class=\"token comment\">// ...</span><br /><br />  <span class=\"token comment\">/* Data Section */</span><br /><br />  <span class=\"token comment\">// The variable-length member is in last position.</span><br />  <span class=\"token comment\">// The size `1` satisfies the compiler.</span><br />  <span class=\"token keyword\">char</span> elements<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>At runtime, when the required size <code>N</code> is known, you allocate a single block of memory for the struct and the <code>N</code> elements combined. The compiler treats this as an opaque block, and provides no safety guarantees. However, accessing the extra allocated space is safe because the variable-length member is the final field in the struct.</p>\n<pre class=\"language-c\"><code class=\"language-c\"><span class=\"token comment\">// The (N - 1) adjusts for the 1-element array in Payload struct</span><br />Payload <span class=\"token operator\">*</span>item <span class=\"token operator\">=</span> <span class=\"token function\">malloc</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span>Payload<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>N <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">char</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n<p>This pattern was officially standardized in C99, where it is known as a <a href=\"https://en.wikipedia.org/wiki/Flexible_array_member\">flexible array member</a>.</p>\n<p>The C++11 standard formally incorporates the flexible array member, referring to it as an <strong>array of unknown bound</strong> when it is the last member of a struct.</p>\n<blockquote>\n<p><strong>Arrays of unknown bound</strong></p>\n<p>If <code>expr</code> is omitted in the declaration of an array, the type declared is &quot;array of unknown bound of T&quot;, which is a kind of incomplete type, ...</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">extern</span> <span class=\"token keyword\">int</span> x<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>      <span class=\"token comment\">// the type of x is \"array of unknown bound of int\"</span><br /><span class=\"token keyword\">int</span> a<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// the type of a is \"array of 3 int\"</span></code></pre>\n</blockquote>\n<p>This means that in C++, the size can be omitted from the final array declaration (e.g. <code>entries_[]</code>), and the code will compile, enabling the same pattern.</p>\n<h2 id=\"b+tree-node-declaration\" tabindex=\"-1\">B+Tree Node Declaration <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#b+tree-node-declaration\" aria-hidden=\"true\">#</a></h2>\n<p>Using the flexible array member syntax, we can now declare a B+Tree node with a memory layout which is a contiguous single block in the heap.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">template</span> <span class=\"token operator\">&lt;</span><span class=\"token keyword\">typename</span> <span class=\"token class-name\">KeyType</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">typename</span> <span class=\"token class-name\">ValueType</span><span class=\"token operator\">></span><br /><span class=\"token keyword\">class</span> <span class=\"token class-name\">BPlusTreeNode</span> <span class=\"token punctuation\">{</span><br /><span class=\"token keyword\">public</span><span class=\"token operator\">:</span><br />  <span class=\"token keyword\">using</span> KeyValuePair <span class=\"token operator\">=</span> std<span class=\"token double-colon punctuation\">::</span>pair<span class=\"token operator\">&lt;</span>KeyType<span class=\"token punctuation\">,</span> ValueType<span class=\"token operator\">></span><span class=\"token punctuation\">;</span><br /><br /><span class=\"token keyword\">private</span><span class=\"token operator\">:</span><br />  <span class=\"token comment\">// Node Header Members ... (elided)</span><br /><br />  <span class=\"token comment\">// Points to the memory location beyond the last key-value</span><br />  <span class=\"token comment\">// entry in the `entries_` array.</span><br />  KeyValuePair<span class=\"token operator\">*</span> iter_end_<span class=\"token punctuation\">;</span><br /><br />  <span class=\"token comment\">// Array containing key-value entries of unknown bound.</span><br />  KeyValuePair entries_<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span></code></pre>\n<p>Using a <code>std::vector&lt;KeyValuePair&gt;</code> for the node's entries would result in an indirection. This immediately fragments the memory layout. Accessing an entry within a node is slower, and has higher latency because of the pointer indirection. Chasing the pointer increases the probability of a cache miss, which will force the CPU to stall while it waits for the cache line to be fetched from a different region in main memory.</p>\n<p>A cache miss will cost hundreds of CPU cycles compared to just a few cycles for a cache hit. This cumulative latency is unacceptable for any high-performance data structure.</p>\n<p>This technique avoids the pointer indirection and provides fine-grained control over memory layout. The node header and data are co-located in one continuous memory block. This layout is cache-friendly and will result in fewer cache misses.</p>\n<h2 id=\"raw-memory-buffer\" tabindex=\"-1\">Raw Memory Buffer <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#raw-memory-buffer\" aria-hidden=\"true\">#</a></h2>\n<p>This is the key step. The construction of the object has to be separate from its memory allocation. We cannot therefore use the standard <code>new</code> syntax which will attempt to allocate storage, and then initialize the object in the same storage.</p>\n<p>Instead, we use the <a href=\"https://en.cppreference.com/w/cpp/language/new.html#Placement_new\">placement new</a> syntax which only constructs an object in a preallocated memory buffer provided by us. We know exactly how much space to allocate, which is information the standard <code>new</code> operator does not have in this scenario because of the flexible array member.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token comment\">// A static helper to allocate storage for a B+Tree node.</span><br /><span class=\"token keyword\">static</span> BPlusTreeNode <span class=\"token operator\">*</span><span class=\"token function\">Get</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> p_fanout<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token comment\">// calculate total buffer size</span><br />  size_t buf_size <span class=\"token operator\">=</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span>BPlusTreeNode<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> p_fanout <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span>KeyValuePair<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token comment\">// allocate raw memory buffer</span><br />  <span class=\"token keyword\">void</span> <span class=\"token operator\">*</span>buf <span class=\"token operator\">=</span> <span class=\"token double-colon punctuation\">::</span><span class=\"token keyword\">operator</span> <span class=\"token keyword\">new</span><span class=\"token punctuation\">(</span>buf_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token comment\">// construct B+Tree node object in the preallocated buffer</span><br />  <span class=\"token keyword\">auto</span> node <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span><span class=\"token punctuation\">(</span>buf<span class=\"token punctuation\">)</span> <span class=\"token function\">BPlusTreeNode</span><span class=\"token punctuation\">(</span>p_fanout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token keyword\">return</span> node<span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>The result is a cache-friendly B+Tree node with a fanout that can be configured at runtime.</p>\n<h2 id=\"the-price-of-fine-grained-control\" tabindex=\"-1\">The Price Of Fine-Grained Control <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#the-price-of-fine-grained-control\" aria-hidden=\"true\">#</a></h2>\n<p>To create an instance of a B+Tree node with a fanout of <code>256</code>, it is not possible to write simple idiomatic code like this: <code>new BPlusTreeNode(256)</code>.</p>\n<p>Instead we use the custom <code>BPlusTreeNode::Get</code> helper which knows how much raw memory to allocate for the object including the data section.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\">BPlusTreeNode <span class=\"token operator\">*</span>root <span class=\"token operator\">=</span> <span class=\"token class-name\">BPlusTreeNode</span><span class=\"token operator\">&lt;</span>KeyValuePair<span class=\"token operator\">></span><span class=\"token double-colon punctuation\">::</span><span class=\"token function\">Get</span><span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<h3 id=\"manual-handling-of-deallocation\" tabindex=\"-1\">Manual Handling Of Deallocation <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#manual-handling-of-deallocation\" aria-hidden=\"true\">#</a></h3>\n<p>The destructor code is also not idiomatic anymore. When the lifetime of the B+Tree node ends, the deallocation code has to be carefully crafted to avoid resource or memory leaks.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">BPlusTreeNode</span> <span class=\"token punctuation\">{</span><br /><br />  <span class=\"token keyword\">void</span> <span class=\"token function\">FreeNode</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />    <span class=\"token comment\">// Call the destructor for each key-value entry.</span><br />    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>KeyValuePair<span class=\"token operator\">*</span> element <span class=\"token operator\">=</span> entries_<span class=\"token punctuation\">;</span> element <span class=\"token operator\">&lt;</span> iter_end_<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>element<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />      element<span class=\"token operator\">-></span><span class=\"token operator\">~</span><span class=\"token function\">KeyValuePair</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />    <span class=\"token punctuation\">}</span><br /><br />    <span class=\"token comment\">// Call the node destructor</span><br />    <span class=\"token keyword\">this</span><span class=\"token operator\">-></span><span class=\"token operator\">~</span><span class=\"token function\">BPlusTreeNode</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />    <span class=\"token comment\">// Deallocate the raw memory</span><br />    <span class=\"token double-colon punctuation\">::</span><span class=\"token keyword\">operator</span> <span class=\"token keyword\">delete</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">this</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />  <span class=\"token punctuation\">}</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>This carefully ordered cleanup is necessary because we took manual control of memory. The process is the mirror opposite of our <code>Get</code> function. We constructed the object outside in: <em>raw memory buffer -&gt; node object -&gt; individual elements</em>. So we teardown in the opposite direction, from the inside out: <em>individual elements -&gt; node object -&gt; raw memory buffer</em>.</p>\n<h3 id=\"adding-new-members-in-a-derived-class\" tabindex=\"-1\">Adding New Members In A Derived Class <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#adding-new-members-in-a-derived-class\" aria-hidden=\"true\">#</a></h3>\n<p>Adding a new member to a derived class will result in data corruption. It is not possible to add new fields to a specialized <code>InnerNode</code> or <code>LeafNode</code> class.</p>\n<pre class=\"language-text\"><code class=\"language-text\">+----------------------+<br />| Node Metadata Header |<br />+----------------------+<br />| ...                  |<br />+----------------------+<br />| Node Data            |<br />+----------------------+<-- offset where the data buffer starts<br />| entries_[0]          |<-- offset where the derived class members<br />| entries_[1]          |    will be written to, overwriting the<br />| ...                  |    entries<br />| entries_[N]          |<br />+----------------------+</code></pre>\n<figcaption>Fig 2. Adding new members in a derived class will overwrite the <code>entries_</code> array in memory.</figcaption>\n<p>The raw memory we manually allocated is opaque to the compiler and it cannot safely reason about where the newly added members to the derived class are physically located. The end result is it will overwrite the data buffer and cause data corruption.</p>\n<p>The workaround is to break encapsulation and add derived members to the base class so that the flexible array member is always in the last position. This is a significant drawback when we begin using flexible array members.</p>\n<pre class=\"language-text\"><code class=\"language-text\">+----------------------+<br />| Node Metadata Header |<br />+----------------------+<br />| ...                  |<br />| low_key_             |<-- `InnerNode`: left-most node pointer<br />| left_sibling_        |<-- `LeafNode` : link to left sibling<br />| right_sibling_       |<-- `LeafNode` : link to right sibling<br />+----------------------+<br />| Node Data            |<br />+----------------------+<-- Flexible array member guaranteed to<br />| entries_[0]          |    be in the last position<br />| entries_[1]          |<br />| ...                  |<br />| entries_[N]          |<br />+----------------------+</code></pre>\n<figcaption>Fig 3. Memory layout of base class with members necessary for the derived <code>InnerNode</code> and <code>LeafNode</code> implementations.</figcaption>\n<h3 id=\"reinventing-the-wheel\" tabindex=\"-1\">Reinventing The Wheel <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#reinventing-the-wheel\" aria-hidden=\"true\">#</a></h3>\n<p>By using a raw C-style array, we effectively reinvent parts of <code>std::vector</code>, implementing our own utilities for insertion, deletion and iteration. This not only raises the complexity and maintenance burden but also means we are responsible for ensuring our custom implementation is as performant as the highly-optimized standard library version.</p>\n<p>The engineering cost to make this implementation production-grade is significant.</p>\n<h3 id=\"hidden-data-type-assumptions\" tabindex=\"-1\">Hidden Data Type Assumptions <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#hidden-data-type-assumptions\" aria-hidden=\"true\">#</a></h3>\n<p>The <code>BPlusTreeNode</code>'s generic signature implies it will work for any <code>KeyType</code> or <code>ValueType</code>, but this is dangerously misleading. Using a non-trivial type like <code>std::string</code> will cause undefined behavior.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">template</span> <span class=\"token operator\">&lt;</span><span class=\"token keyword\">typename</span> <span class=\"token class-name\">KeyType</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">typename</span> <span class=\"token class-name\">ValueType</span><span class=\"token operator\">></span><br /><span class=\"token keyword\">class</span> <span class=\"token class-name\">BPlusTreeNode</span> <span class=\"token punctuation\">{</span><br /><span class=\"token keyword\">public</span><span class=\"token operator\">:</span><br />  <span class=\"token keyword\">using</span> KeyValuePair <span class=\"token operator\">=</span> std<span class=\"token double-colon punctuation\">::</span>pair<span class=\"token operator\">&lt;</span>KeyType<span class=\"token punctuation\">,</span> ValueType<span class=\"token operator\">></span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token comment\">// ...</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>To understand why, let's look at how entries are inserted. To make space for a new element, existing entries must be shifted to the right. With our low-level memory layout, this is done using bitwise copy, as the following implementation shows.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">bool</span> <span class=\"token function\">Insert</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> KeyValuePair <span class=\"token operator\">&amp;</span>element<span class=\"token punctuation\">,</span> KeyValuePair <span class=\"token operator\">*</span>pos<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token comment\">// The node is currently full so we cannot insert this element.</span><br />  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">GetCurrentSize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> <span class=\"token function\">GetMaxSize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> <span class=\"token keyword\">return</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span> <span class=\"token punctuation\">}</span><br /><br />  <span class=\"token comment\">// Shift elements from `pos` to the right by one to make</span><br />  <span class=\"token comment\">// place for inserting new `element`.</span><br />  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>std<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">distance</span><span class=\"token punctuation\">(</span>pos<span class=\"token punctuation\">,</span> <span class=\"token function\">End</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />      <span class=\"token comment\">// Bitwise copying</span><br />      std<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">memmove</span><span class=\"token punctuation\">(</span><br />        <span class=\"token comment\">// Destination Address</span><br />        <span class=\"token generic-function\"><span class=\"token function\">reinterpret_cast</span><span class=\"token generic class-name\"><span class=\"token operator\">&lt;</span><span class=\"token keyword\">void</span> <span class=\"token operator\">*</span><span class=\"token operator\">></span></span></span><span class=\"token punctuation\">(</span>std<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">next</span><span class=\"token punctuation\">(</span>pos<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><br />        <span class=\"token comment\">// Source Address</span><br />        <span class=\"token generic-function\"><span class=\"token function\">reinterpret_cast</span><span class=\"token generic class-name\"><span class=\"token operator\">&lt;</span><span class=\"token keyword\">void</span> <span class=\"token operator\">*</span><span class=\"token operator\">></span></span></span><span class=\"token punctuation\">(</span>pos<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><br />        <span class=\"token comment\">// Byte Count</span><br />        std<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">distance</span><span class=\"token punctuation\">(</span>pos<span class=\"token punctuation\">,</span> <span class=\"token function\">End</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span>KeyValuePair<span class=\"token punctuation\">)</span><br />      <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />  <span class=\"token punctuation\">}</span><br /><br />  <span class=\"token comment\">// Insert element at `pos`.</span><br />  <span class=\"token keyword\">new</span><span class=\"token punctuation\">(</span>pos<span class=\"token punctuation\">)</span> KeyValuePair<span class=\"token punctuation\">{</span>element<span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token comment\">// Bookkeeping</span><br />  std<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">advance</span><span class=\"token punctuation\">(</span>iter_end_<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token keyword\">return</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>The use of <code>std::memmove</code> introduces a hidden constraint: <code>KeyValuePair</code> must be trivially copyable. This means the implementation only works correctly for simple, C-style data structures despite its generic-looking interface.</p>\n<p>Using <code>std::memmove</code> on a <code>std::string</code> object creates a shallow copy. We now have two <code>std::string</code> objects whose internal pointers both point to the same character buffer on the heap. When the destructor of the original string is eventually called, it deallocates that buffer. The copied string is now left with a dangling pointer to freed memory, leading to use-after-free errors or a double-free crash when its own destructor runs.</p>\n<h2 id=\"conclusion\" tabindex=\"-1\">Conclusion <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#conclusion\" aria-hidden=\"true\">#</a></h2>\n<p>We started with a clear goal: a cache-friendly, contiguous B+Tree node with a dynamic, runtime-configurable fanout. The flexible array member proved to be the perfect tool, giving us direct control over memory layout while supporting variable-length entries.</p>\n<p>However, this fine-grained control comes at a steep cost. We must abandon idiomatic C++, manually manage memory, give up inheritance, and enforce hidden data type constraints. This is the fundamental trade-off: we sacrifice simplicity and safety for raw performance.</p>\n",
      "date_published": "2025-08-18T00:00:00Z"
    },{
      "id": "https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/",
      "url": "https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/",
      "title": "A B+Tree Node Underflows: Merge or Borrow?",
      "content_html": "<p>A B+Tree's stable algorithmic performance relies on a single invariant: the path from its root to any leaf is always the same length. However, a delete operation can cause a node to underflow (falling below its minimum occupancy), triggering a rebalancing procedure to maintain this critical invariant.</p>\n<p>Modern B+Trees use fast, optimistic latching protocols which operate under the assumption that rebalancing happens rarely. The mere possibility of an underflow can force the rebalancing into the slow, pessimistic path, acquiring exclusive locks that stall other operations.</p>\n<p>How the implementation decides to fix the underflow is therefore a critical design choice: merge with a sibling node to reclaim free space, or borrow keys from a sibling node to minimize the impact on write latency. Simply put, it's a classic trade-off between space and time. In this post, we will also explore how major OLTP systems expertly implement sophisticated strategies which go beyond this classic trade-off.</p>\n<nav class=\"toc\" aria-labelledby=\"toc-heading\">\n  <h2 id=\"toc-heading\">Table of Contents</h2>\n  <ol>\n    <li>\n      <a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#fixing-node-underflow\">Fixing Node Underflow</a>\n      <ul>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#the-merge-first-approach\">The Merge-First Approach</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#the-borrow-first-approach\">The Borrow-First Approach</a></li>\n      </ul>\n    </li>\n    <li>\n      <a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#in-oltp-systems\">In OLTP systems</a>\n      <ul>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#background-merge-in-mysql-innodb\">Background Merge In MySQL InnoDB</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#do-nothing-strategy-in-postgresql\">Do Nothing Strategy In PostgreSQL</a></li>\n      </ul>\n    </li>\n    <li>\n      <a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#key-takeaways\">Key Takeaways</a>\n    </li>\n  </ol>\n</nav>\n<h2 id=\"fixing-node-underflow\" tabindex=\"-1\">Fixing Node Underflow <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#fixing-node-underflow\" aria-hidden=\"true\">#</a></h2>\n<p>A node underflow happens when the used space (or occupancy) within a node falls below a minimum threshold. This is a possibility after removing an entry from the node. A viable solution is to do nothing. By doing nothing, a tree balancing procedure is never activated. The major downside though is index bloat. A failure to garbage collect the unused memory results in the nodes becoming progressively sparse as entries continue to be added and removed.</p>\n<blockquote>\n<p>In contrast, a node overflow will always trigger a tree rebalancing because it creates a new node whose reference needs to be inserted in the parent node. Here, doing nothing is not even an available option.</p>\n</blockquote>\n<p>The two basic strategies for fixing node underflow both involve merging and borrowing. They differ by which operation is executed first: a merge or a borrow. The merge-first approach prioritizes immediate garbage collection of unused space. It trades-off write speed for more efficient utilization of space. In contrast, the borrow-first approach prioritizes write throughput through redistribution of keys within existing nodes avoiding a merge whenever possible, trading-off long term space-efficiency for short-term write speed.</p>\n<h3 id=\"the-merge-first-approach\" tabindex=\"-1\">The Merge-First Approach <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#the-merge-first-approach\" aria-hidden=\"true\">#</a></h3>\n<p>For a merge to work, the combined entries in the underflowing node and the target sibling node must fit within a single node. After merging two nodes into one, the memory belonging to the underflowing node can be garbage collected.</p>\n<blockquote>\n<p>An efficient implementation will avoid allocation for a new node, and reuse the memory of the sibling node.</p>\n</blockquote>\n<p>The problem with the merge-first approach is that in the worst-case it can recursively cascade all the way back to the root of the B+Tree. In practice though this should happen rarely. The reason for this behavior is that merge eliminates an existing node, and its reference has to be removed from the parent inner node. Removing an entry from a node, has the potential however small to again cause an underflow.</p>\n<p>What if the combined entries will not fit into a single node?</p>\n<p>Then we fallback to borrowing entries from a sibling to fix the underflow. This will not cause a cascading rebalance, as there is no change in nodes, only a redistribution of keys.</p>\n<blockquote>\n<p><em>Disclaimer</em>: The following is a simplified view of how the B+Tree algorithm and concurrency protocols interleave with each other. An implementation in code is more complex.</p>\n</blockquote>\n<p>In optimistic (crab latching) concurrency, if removing an entry will cause a node to underflow it is categorized as an &quot;unsafe&quot; node. The optimistic approach is abandoned and we restart traversal back from the root. It involves acquiring a chain of exclusive latches along the search path to safely complete the operation. This significantly slower path blocks other readers and writers from accessing the latched nodes until the rebalancing operation completes.</p>\n<p>The merge-first approach compresses nodes and therefore more keys are stored within the minimum amount of nodes. This occupies less space on disk and therefore requires less read I/O to be performed. For range scans then a minimum number of nodes needs to be read from disk for a given key range. The higher node density also results in better cache locality and this further improves compute performance.</p>\n<h3 id=\"the-borrow-first-approach\" tabindex=\"-1\">The Borrow-First Approach <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#the-borrow-first-approach\" aria-hidden=\"true\">#</a></h3>\n<p>For borrowing to work, removing the entries from the sibling node must not result in an underflow. Since there is no change in nodes the tree rebalancing is guaranteed not to cascade and therefore completes faster. If borrowing will cause a node underflow, we fallback to merging nodes.</p>\n<p>The concurrency aspects are similar to the merge-first approach. In comparison, it is reasonable to expect that the exclusive latches held on the nodes in the search path segment, will be for a relatively shorter duration. It is still orders of magnitude slower than the optimistic approach.</p>\n<p>This approach prioritizes faster writes and predictable latency by avoiding merging nodes unless strictly necessary. The downside is that node density is lower. The range scans now require more node I/O because the same key range is now spread over a wide span of leaf nodes.</p>\n<h2 id=\"in-oltp-systems\" tabindex=\"-1\">In OLTP Systems <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#in-oltp-systems\" aria-hidden=\"true\">#</a></h2>\n<p>The discussion so far is confined to a stand-alone thread-safe B+Tree implementation. We are looking at behavior and performance at the data structure level. In major OLTP database management systems, the B+Tree index is also tightly integrated with the transaction manager, write ahead log and recovery manager. So the scope of the design decisions are not limited to the data structure level, rather how it impacts the overall systems performance.</p>\n<h3 id=\"background-merge-in-mysql-innodb\" tabindex=\"-1\">Background Merge In MySQL InnoDB <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#background-merge-in-mysql-innodb\" aria-hidden=\"true\">#</a></h3>\n<p>In MYSQL's InnoDB, tree balancing opts for a merge-first approach. Rather than performing an online tree balancing, it is offloaded as a separate asynchronous process in the background. The minimum occupancy of a node is configurable through the <a href=\"https://dev.mysql.com/doc/refman/8.4/en/index-page-merge-threshold.html\">MERGE_THRESHOLD</a> parameter.</p>\n<blockquote>\n<p>If the “page-full” percentage for an index page falls below the MERGE_THRESHOLD value when a row is deleted or when a row is shortened by an UPDATE operation, InnoDB attempts to merge the index page with a neighboring index page. The default MERGE_THRESHOLD value is 50, which is the previously hard-coded value. The minimum MERGE_THRESHOLD value is 1 and the maximum value is 50.</p>\n</blockquote>\n<p>You can monitor the background merge by querying the following InnoDB metrics:</p>\n<pre class=\"language-text\"><code class=\"language-text\">mysql> SELECT NAME, COMMENT FROM INFORMATION_SCHEMA.INNODB_METRICS<br />       WHERE NAME like '%index_page_merge%';<br />+-----------------------------+----------------------------------------+<br />| NAME                        | COMMENT                                |<br />+-----------------------------+----------------------------------------+<br />| index_page_merge_attempts   | Number of index page merge attempts    |<br />| index_page_merge_successful | Number of successful index page merges |<br />+-----------------------------+----------------------------------------+</code></pre>\n<p>Merging entries from a sibling reduces the unused space remaining within a node. If new insertions land on this node, it can immediately overflow. The overflow forces a node split which requires a new node allocation and redistribution of entries. Now both nodes are half-full, and a delete from either node can tip another underflow creating a cycle of merging and splitting. This thrashing merge-split behavior is terrible news for index performance.</p>\n<blockquote>\n<p>If both pages are close to 50% full, a page split can occur soon after the pages are merged. If this merge-split behavior occurs frequently, it can have an adverse affect on performance. To avoid frequent merge-splits, you can lower the MERGE_THRESHOLD value so that InnoDB attempts page merges at a lower “page-full” percentage. Merging pages at a lower page-full percentage leaves more room in index pages and helps reduce merge-split behavior.</p>\n</blockquote>\n<p>What happens if you over-tune the <code>MERGE_THRESHOLD</code> knob for your workload?</p>\n<blockquote>\n<p>A MERGE_THRESHOLD setting that is too small could result in large data files due to an excessive amount of empty page space.</p>\n</blockquote>\n<p>This results in index bloat, which directly harms read efficiency. The same key space instead of being densely packed, is now spread over a larger number of sparse nodes, requiring more I/O for range scans, and takes up more buffer pool capacity to keep the index in memory.</p>\n<h3 id=\"do-nothing-strategy-in-postgresql\" tabindex=\"-1\">Do Nothing Strategy In PostgreSQL <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#do-nothing-strategy-in-postgresql\" aria-hidden=\"true\">#</a></h3>\n<p>In PostgreSQL deleting an index entry, marks a tombstone bit and completes instantly. This requires a light-weight shared lock. In a stark departure from other implementations, no attempt is made whatsoever to merge nodes, or borrow entries and redistribute them between nodes. Deletes in PostgreSQL do not result in tree rebalancing.</p>\n<p>The physical deletion of the entry is separated from the marking a tombstone. Physically deleting an entry requires an exclusive lock on the node, and is more expensive. This separation improves concurrency. It also benefits index scans which use the tombstone as a hint for excluding the deleted entry from the final result set.</p>\n<p>There are two ways in which physical deletion of an entry is performed. The most common method for reclaiming the space for reuse is when <code>VACUUM</code> runs in the background.</p>\n<p>The other way is when an insert lands on the node and there is no space for an entry, it can check for tombstone entries. Then it can acquire an exclusive lock, and physically delete the entries reclaiming enough space for inserting the new entry. This is an opportunistic delete optimization.</p>\n<p><a href=\"https://github.com/postgres/postgres/blob/master/src/backend/access/nbtree/README\">Source</a>: <code>src/backend/access/nbtree/README</code></p>\n<!-- The [PostgreSQL] B+Tree implementation does not attempt to reclaim space after underflow. A node is only deleted after it becomes empty. So it does not implement neither the typical borrow-first nor merge-first strategy outlined above.\n\n> We consider deleting an entire page from the btree only when it's become\n> completely empty of items. (Merging partly-full pages would allow better\n> space reuse, but it seems impractical to move existing data items left or\n> right to make this happen --- a scan moving in the opposite direction\n> might miss the items if so.) Also, we _never_ delete the rightmost page\n> on a tree level (this restriction simplifies the traversal algorithms, as\n> explained below).\n\nBut there is an exception. Removing an empty node which is the right-most child of a parent is explicitly prohibited. The reason for the prohibition is to prevent cascading updates which could potentially propagate up the tree because it involves a different parent node.\n\n> To preserve consistency on the parent level, we cannot merge the key space\n> of a page into its right sibling unless the right sibling is a child of\n> the same parent --- otherwise, the parent's key space assignment changes\n> too, meaning we'd have to make bounding-key updates in its parent, and\n> perhaps all the way up the tree. Since we can't possibly do that\n> atomically, we forbid this case.\n\nWhen a node is deleted from the B+Tree, the free space is not immediately garbage collected. This is tightly coupled with the MVCC implementation. Until all transactions to which the node is visible are completed, it is not garbage collected and put back into circulation.\n\n> Recycling a page is decoupled from page deletion. A deleted page can only\n> be put in the FSM to be recycled once there is no possible scan or search\n> that has a reference to it; until then, it must stay in place with its\n> sibling links undisturbed, as a tombstone that allows concurrent searches\n> to detect and then recover from concurrent deletions (which are rather\n> like concurrent page splits to searchers).\n\n[Source]: https://github.com/postgres/postgres/blob/master/src/backend/access/nbtree/README\n\n## Key Takeaways\n\nThe B+Tree implementations in PostgreSQL or MySQL (InnoDB) employs sophisticated strategies for reclaiming free space after deletions. The end goal is better performance for a wide range of workloads and different access patterns. MySQL (InnoDB) moves merging to happen asynchronously in the background. PostgreSQL avoids tree rebalancing and delays reuse of a deleted node (page). The trade-off in both cases is accepting index bloat and moving the burden to operational side of database management. This is not necessarily a bad thing, as it puts the operator in control. The implementation is also more complex, requiring an in-depth understanding of the engine quirks and harder for developers to modify.\n\nThough OLTP systems are the primary users of a B+Tree data structure for indexes they are not the only ones. They are widely used in embedded key-value stores, search indexes and as library code in custom data management tools. These systems are not burdened by the complexity of interleaving the B+Tree implementation which is both correct and performant with the transaction manager and the recovery algorithms. In these cases, the above simpler strategies can unlock higher performance with lower code complexity for most use cases.\n\nFinally, it depends on the workload and the specific access pattern. But knowing the tricks production-grade OLTP systems will come in handy in getting every ounce of performance out of the B+Tree data structures.\n -->\n",
      "date_published": "2025-08-16T00:00:00Z"
    }
  ]
}
