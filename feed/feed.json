{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "Jacob&#39;s blog",
  "language": "en",
  "home_page_url": "https://jacobsherin.com/",
  "feed_url": "https://example.com/feed/feed.json",
  "description": "On database building blocks.",
  "author": {
    "name": "Your Name Here",
    "url": "https://example.com/about-me/"
  },
  "items": [{
      "id": "https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/",
      "url": "https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/",
      "title": "Practical Hurdles In Crab Latching Concurrency",
      "content_html": "<p>An implementation of the crab latching protocol enforces a strict top-down order for acquiring latches on a B+Tree node. This avoid deadlocks from ever occurring during concurrent operations. This is distinct from deadlock detection and resolution which is a runtime mechanism.</p>\n<p>Deadlock avoidance is guaranteed by design through careful programming of critical sections in the code. Any mistakes here will result in deadlocks. Even worse, a data race which silently corrupts the index.</p>\n<p>The main strength of a B+Tree index (compared to a hash index) is its unique capability to perform range scans. This is possible because all the entries are stored in key lexicographic order in the leaf nodes, and the leaf nodes themselves are connected to each other like a doubly-linked list. So scanning is efficient once you locate the starting leaf node. Scanning in ascending or descending key order is as simple as following the left or right sibling pointers.</p>\n<p>This forwards or backwards movement during index scans violates the strict top-down ordering required for safety and correctness by the crab latching protocol.</p>\n<p>A delete algorithm which implements a symmetrical tree rebalancing procedure requires acquiring an exclusive latch on either a left or right sibling for merging nodes. There is an equal chance of nodes merging left-right and right-left. This too violates the strict ordering requirement.</p>\n<p>Therefore, an implementation has to come up with practical methods to avoid serial execution order and preserve concurrency. There is no formal verification of correctness via proof in these scenarios. We can improve our confidence in the implementation through engineering effort: code reviews, test suites, analyzers (ThreadSanitizer). Though the existence of data races cannot be ruled out, in practice this is sufficient for a robust and reliable implementation as evidenced by major OLTP systems.</p>\n<nav class=\"toc\" aria-labelledby=\"toc-heading\">\n  <h2 id=\"toc-heading\">Table of Contents</h2>\n  <ol>\n    <li>\n      <a href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#an-overview-of-crab-latching\">An Overview Of Crab Latching</a>\n      <ul>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#how-do-deadlocks-happen\">How Do Deadlocks Happen?</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#how-are-deadlocks-prevented\">How Are Deadlocks Prevented?</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#efficient-fine-grained-crab-latching\">Efficient Fine-Grained Crab Latching</a></li>\n      </ul>\n    </li>\n    <li>\n      <a href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#concurrent-index-scans\">Concurrent Index Scans</a>\n      <ul>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#extension-for-concurrent-bi-directional-scans\">Extension For Concurrent Bi-directional Scans</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#deadlock:-lock-order-inversion\">Deadlock: Lock Order Inversion</a></li>\n      </ul>\n    </li>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#extension-for-symmetric-deletion\">Extension For Symmetric Deletion</a></li>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#concurrent-scans-can-miss-entries\">Concurrent Scans Can Miss Entries</a></li>\n  </ol>\n</nav>\n<h2 id=\"an-overview-of-crab-latching\" tabindex=\"-1\">An Overview Of Crab Latching <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#an-overview-of-crab-latching\" aria-hidden=\"true\">#</a></h2>\n<blockquote>\n<p>Latches are held only during a critical section, that is, while a data structure is read or updated. Deadlocks are avoided by appropriate coding disciplines, for example, requesting multiple latches in carefully designed sequences. Deadlock resolution requires a facility to rollback prior actions, whereas deadlock avoidance does not. Thus, deadlock avoidance is more appropriate for latches, which are designed for minimal overhead\nand maximal performance and scalability. Latch acquisition and release may\nrequire tens of instructions only, usually with no additional cache faults since a latch can be embedded in the data structure it protects.</p>\n<p>Goetz Graefe, &quot;A Survey of B-Tree Locking Techniques&quot; (2010)</p>\n</blockquote>\n<h3 id=\"how-do-deadlocks-happen\" tabindex=\"-1\">How Do Deadlocks Happen? <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#how-do-deadlocks-happen\" aria-hidden=\"true\">#</a></h3>\n<p>(<code>Thread 1</code>) Holds an exclusive (write) latch on <code>Node P</code>. It now wants to acquire an exclusive latch on it's child <code>Node C</code> for inserting an element.</p>\n<p>(<code>Thread 2</code>) Already holds an exclusive latch on <code>Node C</code>. It is waiting to acquire an exclusive latch on it's parent <code>Node P</code>, so that the pivot key can be updated.</p>\n<p>This creates a deadlock, where neither threads can make any progress. This could have been prevented if a strict ordering of the direction in which latches are acquired existed. A top-down ordering is better because all traversals begin at the root node to reach a leaf node.</p>\n<h3 id=\"how-are-deadlocks-prevented\" tabindex=\"-1\">How Are Deadlocks Prevented? <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#how-are-deadlocks-prevented\" aria-hidden=\"true\">#</a></h3>\n<p>The ordering requirement implies that only a parent node can acquire an exclusive latch on a child node. The implementation of <code>Thread 2</code> becomes an invalid state and should not be possible. So instead the exclusive latch on <code>Node P</code> is never released when traversing down to the child <code>Node C</code>. Since only one writer can hold the exclusive (write) latch at a time, this will not create a deadlock with <code>Thread 1</code>. The first thread to acquire the exclusive latch on <code>Node P</code>, will block the second thread.</p>\n<p>Even though latches are light-weight and held only for a short duration of time, it is not a good idea to hold latches which are strictly not necessary. It will create contention in hot paths which is bad news for throughput. This is where the crab latching protocol shines with its efficiency.</p>\n<h3 id=\"efficient-fine-grained-crab-latching\" tabindex=\"-1\">Efficient Fine-Grained Crab Latching <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#efficient-fine-grained-crab-latching\" aria-hidden=\"true\">#</a></h3>\n<p>In crab latching, a child node is considered &quot;unsafe&quot; if the current operation will cause it to either split (overflow) or merge (underflow). An &quot;unsafe&quot; node may also end up modifying it's parent like <code>Thread 2</code>. So exclusive latches are held for the entire path segment, which contains &quot;unsafe&quot; nodes.</p>\n<p>But we know that a node split or merge is going to be rare. More often an insert or delete will be local to a leaf node and does not have cascading changes which recurse back to the root node. Such nodes are considered to be &quot;safe&quot;</p>\n<p>In the common scenario, when crab latching sees that a child node is &quot;safe&quot;, it first acquires a shared (read-only) latch on the child node and then release it's shared (read-only) latch on the parent. Hence the &quot;crab latching&quot; terminology. A shared latch does not block other threads. An exclusive latch is only acquired on the leaf node at the time of an insertion or deletion.</p>\n<p>This fine-grained latching is efficient and allows other concurrent readers and only makes writers to wait, improving overall throughput. This is the optimistic approach which assumes will happen in the general case. We fallback to the pessimistic approach only if leaf node will underflow or overflow after an operation.</p>\n<h2 id=\"concurrent-index-scans\" tabindex=\"-1\">Concurrent Index Scans <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#concurrent-index-scans\" aria-hidden=\"true\">#</a></h2>\n<p>The fundamental problem is that the concurrency models do not take into consideration B+Tree iterators. At the leaf node, traversing to a sibling uses the bi-directional links between leaf nodes. An ascending scan moves from left-right, while a descending scan moves from right-left. This conflicts with the safety property for avoiding deadlocks that traversals have a strictly enforced direction. Following the protocol exactly means the implementation can provide only one type of scan, either forward (ascending) or reverse (descending), but never both together.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token comment\">// A forward index scan</span><br /><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">auto</span> iter <span class=\"token operator\">=</span> index<span class=\"token punctuation\">.</span><span class=\"token function\">Begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> iter <span class=\"token operator\">!=</span> index<span class=\"token punctuation\">.</span><span class=\"token function\">End</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>iter<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token keyword\">int</span> key <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>iter<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>first<span class=\"token punctuation\">;</span><br />  <span class=\"token keyword\">int</span> value <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>iter<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>second<span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span><br /><br /><span class=\"token comment\">// A reverse index scan</span><br /><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">auto</span> iter <span class=\"token operator\">=</span> index<span class=\"token punctuation\">.</span><span class=\"token function\">RBegin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> iter <span class=\"token operator\">!=</span> index<span class=\"token punctuation\">.</span><span class=\"token function\">REnd</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">--</span>iter<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token keyword\">int</span> key <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>iter<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>first<span class=\"token punctuation\">;</span><br />  <span class=\"token keyword\">int</span> value <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>iter<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>second<span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span><br /><br /><span class=\"token comment\">/**<br /> * index.Begin()  : first element<br /> * index.End()    : one-past-the-last element<br /> * index.RBegin() : last element<br /> * index.REnd()   : one-past-the-first element<br /> */</span></code></pre>\n<h3 id=\"extension-for-concurrent-bi-directional-scans\" tabindex=\"-1\">Extension For Concurrent Bi-directional Scans <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#extension-for-concurrent-bi-directional-scans\" aria-hidden=\"true\">#</a></h3>\n<p>A shared (read-only) or exclusive (write) latch blocks execution until the latch is acquired. For scans which are sideways traversals, we do not want to limit the traversal to any one direction. A blocking latch will create deadlocks if two concurrent scans proceed in opposite directions.</p>\n<p>Therefore we need to use a non-blocking latch to prevent blocking and avoid deadlocks. A non-blocking latch will try to acquire a latch, and will return immediately.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;shared_mutex></span></span><br /><br /><span class=\"token keyword\">class</span> <span class=\"token class-name\">SharedLatch</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token comment\">// Blocking</span><br />  <span class=\"token comment\">//</span><br />  <span class=\"token comment\">// If another thread holds the latch, execution will block</span><br />  <span class=\"token comment\">// until the latch is acquired.</span><br />  <span class=\"token comment\">//</span><br />  <span class=\"token comment\">// Used in insert, delete &amp; search index operations</span><br />  <span class=\"token keyword\">void</span> <span class=\"token function\">LockShared</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />      latch_<span class=\"token punctuation\">.</span><span class=\"token function\">lock_shared</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />  <span class=\"token punctuation\">}</span><br /><br />  <span class=\"token comment\">// Non-blocking</span><br />  <span class=\"token comment\">//</span><br />  <span class=\"token comment\">// Tries to acquire a latch. If successful returns `true`,</span><br />  <span class=\"token comment\">// otherwise returns `false`.</span><br />  <span class=\"token comment\">//</span><br />  <span class=\"token comment\">// Used in ascending &amp; descending index scans</span><br />  <span class=\"token keyword\">bool</span> <span class=\"token function\">TryLockShared</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />    <span class=\"token keyword\">return</span> latch_<span class=\"token punctuation\">.</span><span class=\"token function\">try_lock_shared</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />  <span class=\"token punctuation\">}</span><br /><br />  <span class=\"token keyword\">private</span><span class=\"token operator\">:</span><br />    <span class=\"token comment\">// A wrapper around std::shared_mutex</span><br />    std<span class=\"token double-colon punctuation\">::</span>shared_mutex latch_<span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>Using <code>TryLockShared()</code> forces us rethink how a scan implementation should work if latch acquisition fails. In contrast, the concurrent insert, delete and search implementations are always expected to return a result matching its output type in the signature.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token comment\">// Returns `std::nullopt` if the key is not found in the index</span><br />std<span class=\"token double-colon punctuation\">::</span>optional<span class=\"token operator\">&lt;</span>KeyType<span class=\"token operator\">></span> <span class=\"token function\">MaybeGet</span><span class=\"token punctuation\">(</span>KeyType key<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br /><span class=\"token comment\">// Returns `false` if key is a duplicate.</span><br /><span class=\"token comment\">//</span><br /><span class=\"token comment\">// Note: This prevents overwriting an existing key. The handling of</span><br /><span class=\"token comment\">// duplicate keys is an implementation specific detail.</span><br /><span class=\"token keyword\">bool</span> <span class=\"token function\">Insert</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> KeyValuePair element<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br /><span class=\"token comment\">// Returns `false` if the key does not exist.</span><br /><span class=\"token keyword\">bool</span> <span class=\"token function\">Delete</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> KeyType key_to_remove<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<p>We can introduce a failure mode, where if latch acquisition fails during a scan we set its internal state to <code>RETRY</code>.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">enum</span> <span class=\"token class-name\">IteratorState</span> <span class=\"token punctuation\">{</span><br />    VALID<span class=\"token punctuation\">,</span> INVALID<span class=\"token punctuation\">,</span> END<span class=\"token punctuation\">,</span> REND<span class=\"token punctuation\">,</span> RETRY<br /><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span></code></pre>\n<p>The implementation for forward scan which uses a non-blocking latch and retriable iterator looks like this:</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token comment\">// Move forward one element at a time. If latch acquisition</span><br /><span class=\"token comment\">// failed, then set internal state to `RETRY`.</span><br /><span class=\"token keyword\">void</span> <span class=\"token keyword\">operator</span><span class=\"token operator\">++</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token comment\">// ...</span><br /><br />  <span class=\"token comment\">// The `TrySharedLock()` is a non-blocking read-only latch</span><br />  <span class=\"token comment\">// which returns `true` or `false` immediately.</span><br />  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span><span class=\"token punctuation\">(</span>current_node_<span class=\"token operator\">-></span><span class=\"token function\">TrySharedLock</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />    previous_node<span class=\"token operator\">-></span><span class=\"token function\">ReleaseNodeSharedLatch</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />    <span class=\"token comment\">// Invalidates the iterator.</span><br />    <span class=\"token comment\">// Sets internal state to `RETRY`.</span><br />    <span class=\"token function\">SetRetryIterator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />    <span class=\"token keyword\">return</span><span class=\"token punctuation\">;</span><br />  <span class=\"token punctuation\">}</span><br /><br />  <span class=\"token comment\">// ...</span><br /><br /><span class=\"token punctuation\">}</span><br /><br /><br /><span class=\"token keyword\">void</span> <span class=\"token function\">SetRetryIterator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token comment\">// Resets internal state</span><br />  current_node_ <span class=\"token operator\">=</span> <span class=\"token keyword\">nullptr</span><span class=\"token punctuation\">;</span><br />  current_element_ <span class=\"token operator\">=</span> <span class=\"token keyword\">nullptr</span><span class=\"token punctuation\">;</span><br /><br />  state_ <span class=\"token operator\">=</span> RETRY<span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>We have a working bi-directional iterator implementation which will avoid deadlocks, but it is not yet free from data races.</p>\n<h3 id=\"deadlock:-lock-order-inversion\" tabindex=\"-1\">Deadlock: Lock Order Inversion <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#deadlock:-lock-order-inversion\" aria-hidden=\"true\">#</a></h3>\n<p>The current API introduces a deadlock if the user initializes two iterators within the same scope, within the same thread.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">auto</span> iter_forward <span class=\"token operator\">=</span> index<span class=\"token punctuation\">.</span><span class=\"token function\">Begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br /><span class=\"token comment\">// The second iterator creates a lock order inversion.</span><br /><span class=\"token keyword\">auto</span> iter_reverse <span class=\"token operator\">=</span> index<span class=\"token punctuation\">.</span><span class=\"token function\">RBegin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<p>A deadlock is prevented by enforcing a strict direction for latching. Any concurrent operation must therefore acquire a latch on an ancestor node before acquiring a latch on a descendant node (top-down traversal).</p>\n<p>The iterator here holds a shared (read-only) latch on the leaf it points to. If that iterator remains alive while another operation begins a new top-down traversal from the root, we can get a deadlock.</p>\n<p>(<code>Thread 1</code>): Creates a forward iterator, which holds a shared latch on a leaf node.</p>\n<p>(<code>Thread 2</code>): Begins an insert in the pessimistic path acquiring an exclusive latch beginning at the root node all the way down to the parent of the same leaf node.</p>\n<p>(<code>Thread 2</code>): Now attempts to acquire an exclusive latch on the leaf node but it blocks, waiting for the forward iterator to complete and release its shared latch on the leaf node.</p>\n<p>(<code>Thread 1</code>): Creates a second reverse iterator, which is now blocking to acquire a shared lock on the root. It is waiting for the insert operation to release the exclusive latch.</p>\n<p>This creates a deadlock, even though in implementation we enforced a strict ordering. We can ensure that this does not happen by ensuring that iterator lifetimes do not intersect each other, by introducing a local scope.</p>\n<p>Most importantly, the shared latch is released at the end of the scope and therefore it also enforces a global ordering for latch acquisition and will not result in a deadlock like described above.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token punctuation\">{</span><br />  <span class=\"token keyword\">auto</span> iter_forward <span class=\"token operator\">=</span> index<span class=\"token punctuation\">.</span><span class=\"token function\">Begin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span><br /><br /><span class=\"token comment\">// The lifetime of the first iterator ends before this</span><br /><span class=\"token comment\">// scope starts. This guarantees that the shared latch</span><br /><span class=\"token comment\">// on the leaf node is released before we start traversal</span><br /><span class=\"token comment\">// from the root node.</span><br /><span class=\"token punctuation\">{</span><br />  <span class=\"token keyword\">auto</span> iter_reverse <span class=\"token operator\">=</span> index<span class=\"token punctuation\">.</span><span class=\"token function\">RBegin</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>To ensure safety, the latching protocol has to be enforced for concurrent operations within the same thread. Unfortunately, our non-blocking, retriable concurrent scan iterators has introduced an API which is easy for the user to incorrectly implement, and must come with warnings.</p>\n<p>The pattern of creating two iterators in the same scope creates a lock-order-inversion within a single thread. While this does not create a deadlock by itself, because of shared latches, it creates the precondition for a deadlock with any concurrent operation which falls down the pessimistic concurrency path.</p>\n<h2 id=\"extension-for-symmetric-deletion\" tabindex=\"-1\">Extension For Symmetric Deletion <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#extension-for-symmetric-deletion\" aria-hidden=\"true\">#</a></h2>\n<p>A symmetric delete algorithm will proceed with a tree rebalancing operation after an underflow by attempting to merge with either the left sibling, and if that doesn't work with the right sibling at any level in the B+Tree. This violates our strict ordering principle for acquiring latches, because a merge can proceed in either direction.</p>\n<p>(<code>Thread 1</code>): operating on Node B, needs to merge with its previous sibling, Node A. It holds an exclusive latch on B and tries to acquire an exclusive latch on A. (left to right)</p>\n<p>(<code>Thread 2</code>): operating on Node A, needs to merge with its next sibling, Node B. It holds an exclusive latch on A and tries to acquire an exclusive latch on B. (right to left)</p>\n<p>The creates a deadlock.</p>\n<p>The fix is to enforce a strict one-way (say left-to-right) latch acquisition order. This is a delicate operation. Before locking the previous sibling A, the exclusive lock on the current node is released. The locks are reacquired in the correct order. First on the previous sibling, then on the current node.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><br />  <span class=\"token keyword\">auto</span> maybe_previous <span class=\"token operator\">=</span> <span class=\"token generic-function\"><span class=\"token function\">static_cast</span><span class=\"token generic class-name\"><span class=\"token operator\">&lt;</span>InnerNode <span class=\"token operator\">*</span><span class=\"token operator\">></span></span></span><span class=\"token punctuation\">(</span>parent<span class=\"token punctuation\">)</span><span class=\"token operator\">-></span><span class=\"token function\">MaybePreviousWithSeparator</span><span class=\"token punctuation\">(</span>key_to_remove<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>maybe_previous<span class=\"token punctuation\">.</span><span class=\"token function\">has_value</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br /><br />    <span class=\"token comment\">/* ... */</span><br /><br />    <span class=\"token comment\">// Enforcing a strict left-to-right (one-way) ordering</span><br />    right<span class=\"token operator\">-></span><span class=\"token function\">ReleaseNodeExclusiveLatch</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />    left<span class=\"token operator\">-></span><span class=\"token function\">GetNodeExclusiveLatch</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />    right<span class=\"token operator\">-></span><span class=\"token function\">GetNodeExclusiveLatch</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />    <span class=\"token comment\">/* ... */</span><br />  <span class=\"token punctuation\">}</span></code></pre>\n<h2 id=\"concurrent-scans-can-miss-entries\" tabindex=\"-1\">Concurrent Scans Can Miss Entries <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-21-bplustree-concurrency-challenges/#concurrent-scans-can-miss-entries\" aria-hidden=\"true\">#</a></h2>\n<p>Earlier in the case of concurrent scans we saw how local reasoning of strict ordering is not sufficient, because of the extension. A global strict ordering has to be enforced to prevent unintended deadlocks from interaction of scans with other concurrent operations.</p>\n<p>Now let us look at a scenario where both the extensions can interact in a manner which violates strict ordering and introduces lock order inversion bugs in subtle ways.</p>\n<p>(<code>Thread 1</code>): A forward scan iterator has completed scanning entries in Node A, and is next going to process it's right sibling Node B.</p>\n<p>(<code>Thread 2</code>): A delete operation has taken the pessimistic path, because Node B is going to underflow after removing this entry. So it decides to merge with left sibling Node A. It already holds an exclusive latch on Node B and has to acquire an exclusive latch on Node B.</p>\n<p>If the forward scan operator releases its shared latch on Node A, before it acquires a shared latch on Node B, the following sequence of events can happen with the right timing of events.</p>\n<p>(<code>Thread 1</code>): Releases latch on Node A before acquiring a latch on Node B.</p>\n<p>(<code>Thread 2</code>): Release exclusive latch on Node B. Acquires exclusive latch on Node A. Acquires the exclusive latch back on Node B.</p>\n<p>(<code>Thread 1</code>): Is blocked by the exclusive latch held on Node B, by the delete operation in <code>Thread 2</code>.</p>\n<p>(<code>Thread 2</code>): Merges Node A and B together, and modifies the right sibling pointer to Node C.</p>\n<p>(<code>Thread 1</code>): Finally acquires a latch on Node C which is the new right sibling on Node A, not realizing it missed node B completely.</p>\n<p>If latches acquisition is not crafted carefully in the iterator code, the following situation creates a race condition which is very hard to even detect, or reproduce.</p>\n<p>The fix here is to correctly implement crab latching in the iterator code. A shared lock should not be released before <code>TrySharedLock()</code> is attempted on the sibling node. Doing so results in race conditions which are impossible to track down. This requires careful programming discipline.</p>\n",
      "date_published": "2025-08-21T00:00:00Z"
    },{
      "id": "https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/",
      "url": "https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/",
      "title": "Cache-Friendly B+Tree Nodes With Dynamic Fanout",
      "content_html": "<p>For a high-performance B+Tree, the memory layout of each node must be a single contiguous block. This improves locality of reference, increasing the likelihood that the node's contents reside in the CPU cache.</p>\n<p>In C++, achieving this means forgoing the use of <code>std::vector</code>, as it introduces a layer of indirection through a separate memory allocation. The solution to this problem though inevitably increases the implementation complexity and is mired with hidden drawbacks. Nevertheless, this is still a necessary trade-off for unlocking high performance.</p>\n<pre class=\"language-text\"><code class=\"language-text\">  +----------------------+<br />  | Node Metadata Header |<br />  +----------------------+<br />  | node_type_           |<-- Inner Node or Leaf Node<br />  | max_size_            |<-- Maximum Capacity (aka Node Fanout)<br />  | node_latch_          |<-- RW-Lock Mutex<br />  | iter_end_            |--------------------+<br />  +----------------------+                    |<br />  | Node Data            |                    |<br />  +----------------------+                    |<br />  | entries_[0]          | <--+               |<br />  | entries_[1]          |    |               |<br />  | entries_[2]          |    + used space    |<br />  | ...                  |    |               |<br />  | entries_[k]          | <--+               |<br />  +----------------------+<-------------------+ iter_end_ points to<br />  |                      |    entries_[k+1], which is one-past-the-last<br />  | (unused space)       |    entry in the node.<br />  | ...                  |<br />  +----------------------+</code></pre>\n<figcaption>Fig 1. Memory Layout of a B+Tree Node as a single contiguous block in heap</figcaption>\n<nav class=\"toc\" aria-labelledby=\"toc-heading\">\n  <h2 id=\"toc-heading\">Table of Contents</h2>\n  <ol>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#challenges\">Challenges</a></li>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#the-struct-hack\">The Struct Hack</a></li>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#b+tree-node-declaration\">B+Tree Node Declaration</a></li>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#raw-memory-buffer\">Raw Memory Buffer</a></li>\n    <li>\n      <a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#the-price-of-fine-grained-control\">The Price Of Fine-Grained Control</a>\n      <ul>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#manual-handling-of-deallocation\">Manual Handling Of Deallocation</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#adding-new-members-in-a-derived-class\">Adding New Members In A Derived Class</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#reinventing-the-wheel\">Reinventing The Wheel</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#hidden-data-type-assumptions\">Hidden Data Type Assumptions</a></li>\n      </ul>\n    </li>\n    <li><a href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#conclusion\">Conclusion</a></li>\n  </ol>\n</nav>\n<h2 id=\"challenges\" tabindex=\"-1\">Challenges <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#challenges\" aria-hidden=\"true\">#</a></h2>\n<p>Using <code>std::vector</code> for a B+Tree node's entries is a non-starter. A <code>std::vector</code> object holds a pointer to its entries which are stored in a separate block of memory on the heap. This indirection fragments the memory layout, forcing us to fall back on C-style arrays for a contiguous layout when storing variable-length node entries.</p>\n<p>This leads to a dilemma. The size of the array must be known at compilation time, yet we need to allow users to configure the fanout (the array's size) at runtime. Furthermore, the implementation should allow inner nodes and leaf nodes to have different fanouts.</p>\n<p>This isn't just a B+Tree problem. It is a common challenge in systems programming whenever an object needs to contain a variable-length payload whose size is only known at runtime. How can you define a class that occupies a single block of memory when a part of the block has a dynamic size?</p>\n<p>The solution isn't obvious, but it's a well-known trick that systems programmers have used for decades, a technique so common it has eventually been standardized in C99.</p>\n<h2 id=\"the-struct-hack\" tabindex=\"-1\">The Struct Hack <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#the-struct-hack\" aria-hidden=\"true\">#</a></h2>\n<p>The solution to this problem is a technique originating in C programming known as the struct hack. The variable-length member (array) is placed at the last position in the struct. To satisfy the compiler an array size of one is hard-coded, ensuring the array size is known at compilation time.</p>\n<pre class=\"language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> <span class=\"token class-name\">Payload</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token comment\">/* Header Section */</span><br />  <span class=\"token comment\">// ...</span><br /><br />  <span class=\"token comment\">/* Data Section */</span><br /><br />  <span class=\"token comment\">// The variable-length member is in last position.</span><br />  <span class=\"token comment\">// The size `1` satisfies the compiler.</span><br />  <span class=\"token keyword\">char</span> elements<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>At runtime, when the required size <code>N</code> is known, you allocate a single block of memory for the struct and the <code>N</code> elements combined. The compiler treats this as an opaque block, and provides no safety guarantees. However, accessing the extra allocated space is safe because the variable-length member is the final field in the struct.</p>\n<pre class=\"language-c\"><code class=\"language-c\"><span class=\"token comment\">// The (N - 1) adjusts for the 1-element array in Payload struct</span><br />Payload <span class=\"token operator\">*</span>item <span class=\"token operator\">=</span> <span class=\"token function\">malloc</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span>Payload<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>N <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">char</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n<p>This pattern was officially standardized in C99, where it is known as a <a href=\"https://en.wikipedia.org/wiki/Flexible_array_member\">flexible array member</a>.</p>\n<p>The C++11 standard formally incorporates the flexible array member, referring to it as an <strong>array of unknown bound</strong> when it is the last member of a struct.</p>\n<blockquote>\n<p><strong>Arrays of unknown bound</strong></p>\n<p>If <code>expr</code> is omitted in the declaration of an array, the type declared is &quot;array of unknown bound of T&quot;, which is a kind of incomplete type, ...</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">extern</span> <span class=\"token keyword\">int</span> x<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>      <span class=\"token comment\">// the type of x is \"array of unknown bound of int\"</span><br /><span class=\"token keyword\">int</span> a<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// the type of a is \"array of 3 int\"</span></code></pre>\n</blockquote>\n<p>This means that in C++, the size can be omitted from the final array declaration (e.g. <code>entries_[]</code>), and the code will compile, enabling the same pattern.</p>\n<h2 id=\"b+tree-node-declaration\" tabindex=\"-1\">B+Tree Node Declaration <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#b+tree-node-declaration\" aria-hidden=\"true\">#</a></h2>\n<p>Using the flexible array member syntax, we can now declare a B+Tree node with a memory layout which is a contiguous single block in the heap.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">template</span> <span class=\"token operator\">&lt;</span><span class=\"token keyword\">typename</span> <span class=\"token class-name\">KeyType</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">typename</span> <span class=\"token class-name\">ValueType</span><span class=\"token operator\">></span><br /><span class=\"token keyword\">class</span> <span class=\"token class-name\">BPlusTreeNode</span> <span class=\"token punctuation\">{</span><br /><span class=\"token keyword\">public</span><span class=\"token operator\">:</span><br />  <span class=\"token keyword\">using</span> KeyValuePair <span class=\"token operator\">=</span> std<span class=\"token double-colon punctuation\">::</span>pair<span class=\"token operator\">&lt;</span>KeyType<span class=\"token punctuation\">,</span> ValueType<span class=\"token operator\">></span><span class=\"token punctuation\">;</span><br /><br /><span class=\"token keyword\">private</span><span class=\"token operator\">:</span><br />  <span class=\"token comment\">// Node Header Members ... (elided)</span><br /><br />  <span class=\"token comment\">// Points to the memory location beyond the last key-value</span><br />  <span class=\"token comment\">// entry in the `entries_` array.</span><br />  KeyValuePair<span class=\"token operator\">*</span> iter_end_<span class=\"token punctuation\">;</span><br /><br />  <span class=\"token comment\">// Array containing key-value entries of unknown bound.</span><br />  KeyValuePair entries_<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span></code></pre>\n<p>Using a <code>std::vector&lt;KeyValuePair&gt;</code> for the node's entries would result in an indirection. This immediately fragments the memory layout. Accessing an entry within a node is slower, and has higher latency because of the pointer indirection. Chasing the pointer increases the probability of a cache miss, which will force the CPU to stall while it waits for the cache line to be fetched from a different region in main memory.</p>\n<p>A cache miss will cost hundreds of CPU cycles compared to just a few cycles for a cache hit. This cumulative latency is unacceptable for any high-performance data structure.</p>\n<p>This technique avoids the pointer indirection and provides fine-grained control over memory layout. The node header and data are co-located in one continuous memory block. This layout is cache-friendly and will result in fewer cache misses.</p>\n<h2 id=\"raw-memory-buffer\" tabindex=\"-1\">Raw Memory Buffer <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#raw-memory-buffer\" aria-hidden=\"true\">#</a></h2>\n<p>This is the key step. The construction of the object has to be separate from its memory allocation. We cannot therefore use the standard <code>new</code> syntax which will attempt to allocate storage, and then initialize the object in the same storage.</p>\n<p>Instead, we use the <a href=\"https://en.cppreference.com/w/cpp/language/new.html#Placement_new\">placement new</a> syntax which only constructs an object in a preallocated memory buffer provided by us. We know exactly how much space to allocate, which is information the standard <code>new</code> operator does not have in this scenario because of the flexible array member.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token comment\">// A static helper to allocate storage for a B+Tree node.</span><br /><span class=\"token keyword\">static</span> BPlusTreeNode <span class=\"token operator\">*</span><span class=\"token function\">Get</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> p_fanout<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token comment\">// calculate total buffer size</span><br />  size_t buf_size <span class=\"token operator\">=</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span>BPlusTreeNode<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> p_fanout <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span>KeyValuePair<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token comment\">// allocate raw memory buffer</span><br />  <span class=\"token keyword\">void</span> <span class=\"token operator\">*</span>buf <span class=\"token operator\">=</span> <span class=\"token double-colon punctuation\">::</span><span class=\"token keyword\">operator</span> <span class=\"token keyword\">new</span><span class=\"token punctuation\">(</span>buf_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token comment\">// construct B+Tree node object in the preallocated buffer</span><br />  <span class=\"token keyword\">auto</span> node <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span><span class=\"token punctuation\">(</span>buf<span class=\"token punctuation\">)</span> <span class=\"token function\">BPlusTreeNode</span><span class=\"token punctuation\">(</span>p_fanout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token keyword\">return</span> node<span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>The result is a cache-friendly B+Tree node with a fanout that can be configured at runtime.</p>\n<h2 id=\"the-price-of-fine-grained-control\" tabindex=\"-1\">The Price Of Fine-Grained Control <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#the-price-of-fine-grained-control\" aria-hidden=\"true\">#</a></h2>\n<p>To create an instance of a B+Tree node with a fanout of <code>256</code>, it is not possible to write simple idiomatic code like this: <code>new BPlusTreeNode(256)</code>.</p>\n<p>Instead we use the custom <code>BPlusTreeNode::Get</code> helper which knows how much raw memory to allocate for the object including the data section.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\">BPlusTreeNode <span class=\"token operator\">*</span>root <span class=\"token operator\">=</span> <span class=\"token class-name\">BPlusTreeNode</span><span class=\"token operator\">&lt;</span>KeyValuePair<span class=\"token operator\">></span><span class=\"token double-colon punctuation\">::</span><span class=\"token function\">Get</span><span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<h3 id=\"manual-handling-of-deallocation\" tabindex=\"-1\">Manual Handling Of Deallocation <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#manual-handling-of-deallocation\" aria-hidden=\"true\">#</a></h3>\n<p>The destructor code is also not idiomatic anymore. When the lifetime of the B+Tree node ends, the deallocation code has to be carefully crafted to avoid resource or memory leaks.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">BPlusTreeNode</span> <span class=\"token punctuation\">{</span><br /><br />  <span class=\"token keyword\">void</span> <span class=\"token function\">FreeNode</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />    <span class=\"token comment\">// Call the destructor for each key-value entry.</span><br />    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>KeyValuePair<span class=\"token operator\">*</span> element <span class=\"token operator\">=</span> entries_<span class=\"token punctuation\">;</span> element <span class=\"token operator\">&lt;</span> iter_end_<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>element<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />      element<span class=\"token operator\">-></span><span class=\"token operator\">~</span><span class=\"token function\">KeyValuePair</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />    <span class=\"token punctuation\">}</span><br /><br />    <span class=\"token comment\">// Call the node destructor</span><br />    <span class=\"token keyword\">this</span><span class=\"token operator\">-></span><span class=\"token operator\">~</span><span class=\"token function\">BPlusTreeNode</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />    <span class=\"token comment\">// Deallocate the raw memory</span><br />    <span class=\"token double-colon punctuation\">::</span><span class=\"token keyword\">operator</span> <span class=\"token keyword\">delete</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">this</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />  <span class=\"token punctuation\">}</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>This carefully ordered cleanup is necessary because we took manual control of memory. The process is the mirror opposite of our <code>Get</code> function. We constructed the object outside in: <em>raw memory buffer -&gt; node object -&gt; individual elements</em>. So we teardown in the opposite direction, from the inside out: <em>individual elements -&gt; node object -&gt; raw memory buffer</em>.</p>\n<h3 id=\"adding-new-members-in-a-derived-class\" tabindex=\"-1\">Adding New Members In A Derived Class <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#adding-new-members-in-a-derived-class\" aria-hidden=\"true\">#</a></h3>\n<p>Adding a new member to a derived class will result in data corruption. It is not possible to add new fields to a specialized <code>InnerNode</code> or <code>LeafNode</code> class.</p>\n<pre class=\"language-text\"><code class=\"language-text\">+----------------------+<br />| Node Metadata Header |<br />+----------------------+<br />| ...                  |<br />+----------------------+<br />| Node Data            |<br />+----------------------+<-- offset where the data buffer starts<br />| entries_[0]          |<-- offset where the derived class members<br />| entries_[1]          |    will be written to, overwriting the<br />| ...                  |    entries<br />| entries_[N]          |<br />+----------------------+</code></pre>\n<figcaption>Fig 2. Adding new members in a derived class will overwrite the <code>entries_</code> array in memory.</figcaption>\n<p>The raw memory we manually allocated is opaque to the compiler and it cannot safely reason about where the newly added members to the derived class are physically located. The end result is it will overwrite the data buffer and cause data corruption.</p>\n<p>The workaround is to break encapsulation and add derived members to the base class so that the flexible array member is always in the last position. This is a significant drawback when we begin using flexible array members.</p>\n<pre class=\"language-text\"><code class=\"language-text\">+----------------------+<br />| Node Metadata Header |<br />+----------------------+<br />| ...                  |<br />| low_key_             |<-- `InnerNode`: left-most node pointer<br />| left_sibling_        |<-- `LeafNode` : link to left sibling<br />| right_sibling_       |<-- `LeafNode` : link to right sibling<br />+----------------------+<br />| Node Data            |<br />+----------------------+<-- Flexible array member guaranteed to<br />| entries_[0]          |    be in the last position<br />| entries_[1]          |<br />| ...                  |<br />| entries_[N]          |<br />+----------------------+</code></pre>\n<figcaption>Fig 3. Memory layout of base class with members necessary for the derived <code>InnerNode</code> and <code>LeafNode</code> implementations.</figcaption>\n<h3 id=\"reinventing-the-wheel\" tabindex=\"-1\">Reinventing The Wheel <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#reinventing-the-wheel\" aria-hidden=\"true\">#</a></h3>\n<p>By using a raw C-style array, we effectively reinvent parts of <code>std::vector</code>, implementing our own utilities for insertion, deletion and iteration. This not only raises the complexity and maintenance burden but also means we are responsible for ensuring our custom implementation is as performant as the highly-optimized standard library version.</p>\n<p>The engineering cost to make this implementation production-grade is significant.</p>\n<h3 id=\"hidden-data-type-assumptions\" tabindex=\"-1\">Hidden Data Type Assumptions <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#hidden-data-type-assumptions\" aria-hidden=\"true\">#</a></h3>\n<p>The <code>BPlusTreeNode</code>'s generic signature implies it will work for any <code>KeyType</code> or <code>ValueType</code>, but this is dangerously misleading. Using a non-trivial type like <code>std::string</code> will cause undefined behavior.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">template</span> <span class=\"token operator\">&lt;</span><span class=\"token keyword\">typename</span> <span class=\"token class-name\">KeyType</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">typename</span> <span class=\"token class-name\">ValueType</span><span class=\"token operator\">></span><br /><span class=\"token keyword\">class</span> <span class=\"token class-name\">BPlusTreeNode</span> <span class=\"token punctuation\">{</span><br /><span class=\"token keyword\">public</span><span class=\"token operator\">:</span><br />  <span class=\"token keyword\">using</span> KeyValuePair <span class=\"token operator\">=</span> std<span class=\"token double-colon punctuation\">::</span>pair<span class=\"token operator\">&lt;</span>KeyType<span class=\"token punctuation\">,</span> ValueType<span class=\"token operator\">></span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token comment\">// ...</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>To understand why, let's look at how entries are inserted. To make space for a new element, existing entries must be shifted to the right. With our low-level memory layout, this is done using bitwise copy, as the following implementation shows.</p>\n<pre class=\"language-cpp\"><code class=\"language-cpp\"><span class=\"token keyword\">bool</span> <span class=\"token function\">Insert</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> KeyValuePair <span class=\"token operator\">&amp;</span>element<span class=\"token punctuation\">,</span> KeyValuePair <span class=\"token operator\">*</span>pos<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />  <span class=\"token comment\">// The node is currently full so we cannot insert this element.</span><br />  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">GetCurrentSize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> <span class=\"token function\">GetMaxSize</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> <span class=\"token keyword\">return</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span> <span class=\"token punctuation\">}</span><br /><br />  <span class=\"token comment\">// Shift elements from `pos` to the right by one to make</span><br />  <span class=\"token comment\">// place for inserting new `element`.</span><br />  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>std<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">distance</span><span class=\"token punctuation\">(</span>pos<span class=\"token punctuation\">,</span> <span class=\"token function\">End</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span><br />      <span class=\"token comment\">// Bitwise copying</span><br />      std<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">memmove</span><span class=\"token punctuation\">(</span><br />        <span class=\"token comment\">// Destination Address</span><br />        <span class=\"token generic-function\"><span class=\"token function\">reinterpret_cast</span><span class=\"token generic class-name\"><span class=\"token operator\">&lt;</span><span class=\"token keyword\">void</span> <span class=\"token operator\">*</span><span class=\"token operator\">></span></span></span><span class=\"token punctuation\">(</span>std<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">next</span><span class=\"token punctuation\">(</span>pos<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><br />        <span class=\"token comment\">// Source Address</span><br />        <span class=\"token generic-function\"><span class=\"token function\">reinterpret_cast</span><span class=\"token generic class-name\"><span class=\"token operator\">&lt;</span><span class=\"token keyword\">void</span> <span class=\"token operator\">*</span><span class=\"token operator\">></span></span></span><span class=\"token punctuation\">(</span>pos<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><br />        <span class=\"token comment\">// Byte Count</span><br />        std<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">distance</span><span class=\"token punctuation\">(</span>pos<span class=\"token punctuation\">,</span> <span class=\"token function\">End</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">sizeof</span><span class=\"token punctuation\">(</span>KeyValuePair<span class=\"token punctuation\">)</span><br />      <span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br />  <span class=\"token punctuation\">}</span><br /><br />  <span class=\"token comment\">// Insert element at `pos`.</span><br />  <span class=\"token keyword\">new</span><span class=\"token punctuation\">(</span>pos<span class=\"token punctuation\">)</span> KeyValuePair<span class=\"token punctuation\">{</span>element<span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token comment\">// Bookkeeping</span><br />  std<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">advance</span><span class=\"token punctuation\">(</span>iter_end_<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><br /><br />  <span class=\"token keyword\">return</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span><br /><span class=\"token punctuation\">}</span></code></pre>\n<p>The use of <code>std::memmove</code> introduces a hidden constraint: <code>KeyValuePair</code> must be trivially copyable. This means the implementation only works correctly for simple, C-style data structures despite its generic-looking interface.</p>\n<p>Using <code>std::memmove</code> on a <code>std::string</code> object creates a shallow copy. We now have two <code>std::string</code> objects whose internal pointers both point to the same character buffer on the heap. When the destructor of the original string is eventually called, it deallocates that buffer. The copied string is now left with a dangling pointer to freed memory, leading to use-after-free errors or a double-free crash when its own destructor runs.</p>\n<h2 id=\"conclusion\" tabindex=\"-1\">Conclusion <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/#conclusion\" aria-hidden=\"true\">#</a></h2>\n<p>We started with a clear goal: a cache-friendly, contiguous B+Tree node with a dynamic, runtime-configurable fanout. The flexible array member proved to be the perfect tool, giving us direct control over memory layout while supporting variable-length entries.</p>\n<p>However, this fine-grained control comes at a steep cost. We must abandon idiomatic C++, manually manage memory, give up inheritance, and enforce hidden data type constraints. This is the fundamental trade-off: we sacrifice simplicity and safety for raw performance.</p>\n",
      "date_published": "2025-08-18T00:00:00Z"
    },{
      "id": "https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/",
      "url": "https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/",
      "title": "A B+Tree Node Underflows: Merge or Borrow?",
      "content_html": "<p>A B+Tree's stable algorithmic performance relies on a single invariant: the path from its root to any leaf is always the same length. However, a delete operation can cause a node to underflow (falling below its minimum occupancy), triggering a rebalancing procedure to maintain this critical invariant.</p>\n<p>Modern B+Trees use fast, optimistic latching protocols which operate under the assumption that rebalancing happens rarely. The mere possibility of an underflow can force the rebalancing into the slow, pessimistic path, acquiring exclusive locks that stall other operations.</p>\n<p>How the implementation decides to fix the underflow is therefore a critical design choice: merge with a sibling node to reclaim free space, or borrow keys from a sibling node to minimize the impact on write latency. Simply put, it's a classic trade-off between space and time. In this post, we will also explore how major OLTP systems expertly implement sophisticated strategies which go beyond this classic trade-off.</p>\n<nav class=\"toc\" aria-labelledby=\"toc-heading\">\n  <h2 id=\"toc-heading\">Table of Contents</h2>\n  <ol>\n    <li>\n      <a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#fixing-node-underflow\">Fixing Node Underflow</a>\n      <ul>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#the-merge-first-approach\">The Merge-First Approach</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#the-borrow-first-approach\">The Borrow-First Approach</a></li>\n      </ul>\n    </li>\n    <li>\n      <a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#in-oltp-systems\">In OLTP systems</a>\n      <ul>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#background-merge-in-mysql-innodb\">Background Merge In MySQL InnoDB</a></li>\n        <li><a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#do-nothing-strategy-in-postgresql\">Do Nothing Strategy In PostgreSQL</a></li>\n      </ul>\n    </li>\n    <li>\n      <a href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#key-takeaways\">Key Takeaways</a>\n    </li>\n  </ol>\n</nav>\n<h2 id=\"fixing-node-underflow\" tabindex=\"-1\">Fixing Node Underflow <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#fixing-node-underflow\" aria-hidden=\"true\">#</a></h2>\n<p>A node underflow happens when the used space (or occupancy) within a node falls below a minimum threshold. This is a possibility after removing an entry from the node. A viable solution is to do nothing. By doing nothing, a tree balancing procedure is never activated. The major downside though is index bloat. A failure to garbage collect the unused memory results in the nodes becoming progressively sparse as entries continue to be added and removed.</p>\n<blockquote>\n<p>In contrast, a node overflow will always trigger a tree rebalancing because it creates a new node whose reference needs to be inserted in the parent node. Here, doing nothing is not even an available option.</p>\n</blockquote>\n<p>The two basic strategies for fixing node underflow both involve merging and borrowing. They differ by which operation is executed first: a merge or a borrow. The merge-first approach prioritizes immediate garbage collection of unused space. It trades-off write speed for more efficient utilization of space. In contrast, the borrow-first approach prioritizes write throughput through redistribution of keys within existing nodes avoiding a merge whenever possible, trading-off long term space-efficiency for short-term write speed.</p>\n<h3 id=\"the-merge-first-approach\" tabindex=\"-1\">The Merge-First Approach <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#the-merge-first-approach\" aria-hidden=\"true\">#</a></h3>\n<p>For a merge to work, the combined entries in the underflowing node and the target sibling node must fit within a single node. After merging two nodes into one, the memory belonging to the underflowing node can be garbage collected.</p>\n<blockquote>\n<p>An efficient implementation will avoid allocation for a new node, and reuse the memory of the sibling node.</p>\n</blockquote>\n<p>The problem with the merge-first approach is that in the worst-case it can recursively cascade all the way back to the root of the B+Tree. In practice though this should happen rarely. The reason for this behavior is that merge eliminates an existing node, and its reference has to be removed from the parent inner node. Removing an entry from a node, has the potential however small to again cause an underflow.</p>\n<p>What if the combined entries will not fit into a single node?</p>\n<p>Then we fallback to borrowing entries from a sibling to fix the underflow. This will not cause a cascading rebalance, as there is no change in nodes, only a redistribution of keys.</p>\n<blockquote>\n<p><em>Disclaimer</em>: The following is a simplified view of how the B+Tree algorithm and concurrency protocols interleave with each other. An implementation in code is more complex.</p>\n</blockquote>\n<p>In optimistic (crab latching) concurrency, if removing an entry will cause a node to underflow it is categorized as an &quot;unsafe&quot; node. The optimistic approach is abandoned and we restart traversal back from the root. It involves acquiring a chain of exclusive latches along the search path to safely complete the operation. This significantly slower path blocks other readers and writers from accessing the latched nodes until the rebalancing operation completes.</p>\n<p>The merge-first approach compresses nodes and therefore more keys are stored within the minimum amount of nodes. This occupies less space on disk and therefore requires less read I/O to be performed. For range scans then a minimum number of nodes needs to be read from disk for a given key range. The higher node density also results in better cache locality and this further improves compute performance.</p>\n<h3 id=\"the-borrow-first-approach\" tabindex=\"-1\">The Borrow-First Approach <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#the-borrow-first-approach\" aria-hidden=\"true\">#</a></h3>\n<p>For borrowing to work, removing the entries from the sibling node must not result in an underflow. Since there is no change in nodes the tree rebalancing is guaranteed not to cascade and therefore completes faster. If borrowing will cause a node underflow, we fallback to merging nodes.</p>\n<p>The concurrency aspects are similar to the merge-first approach. In comparison, it is reasonable to expect that the exclusive latches held on the nodes in the search path segment, will be for a relatively shorter duration. It is still orders of magnitude slower than the optimistic approach.</p>\n<p>This approach prioritizes faster writes and predictable latency by avoiding merging nodes unless strictly necessary. The downside is that node density is lower. The range scans now require more node I/O because the same key range is now spread over a wide span of leaf nodes.</p>\n<h2 id=\"in-oltp-systems\" tabindex=\"-1\">In OLTP Systems <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#in-oltp-systems\" aria-hidden=\"true\">#</a></h2>\n<p>The discussion so far is confined to a stand-alone thread-safe B+Tree implementation. We are looking at behavior and performance at the data structure level. In major OLTP database management systems, the B+Tree index is also tightly integrated with the transaction manager, write ahead log and recovery manager. So the scope of the design decisions are not limited to the data structure level, rather how it impacts the overall systems performance.</p>\n<h3 id=\"background-merge-in-mysql-innodb\" tabindex=\"-1\">Background Merge In MySQL InnoDB <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#background-merge-in-mysql-innodb\" aria-hidden=\"true\">#</a></h3>\n<p>In MYSQL's InnoDB, node underflow is handling through merging. Rather than performing an online tree balancing, it is offloaded as a separate asynchronous process in the background. The minimum occupancy of a node is configurable through the <a href=\"https://dev.mysql.com/doc/refman/8.4/en/index-page-merge-threshold.html\">MERGE_THRESHOLD</a> parameter.</p>\n<blockquote>\n<p>If the “page-full” percentage for an index page falls below the MERGE_THRESHOLD value when a row is deleted or when a row is shortened by an UPDATE operation, InnoDB attempts to merge the index page with a neighboring index page. The default MERGE_THRESHOLD value is 50, which is the previously hard-coded value. The minimum MERGE_THRESHOLD value is 1 and the maximum value is 50.</p>\n</blockquote>\n<p>You can monitor the background merge by querying the following InnoDB metrics:</p>\n<pre class=\"language-text\"><code class=\"language-text\">mysql> SELECT NAME, COMMENT FROM INFORMATION_SCHEMA.INNODB_METRICS<br />       WHERE NAME like '%index_page_merge%';<br />+-----------------------------+----------------------------------------+<br />| NAME                        | COMMENT                                |<br />+-----------------------------+----------------------------------------+<br />| index_page_merge_attempts   | Number of index page merge attempts    |<br />| index_page_merge_successful | Number of successful index page merges |<br />+-----------------------------+----------------------------------------+</code></pre>\n<p>Merging entries from a sibling reduces the unused space remaining within a node. If new insertions land on this node, it can immediately overflow. The overflow forces a node split which requires a new node allocation and redistribution of entries. Now both nodes are half-full, and a delete from either node can tip another underflow creating a cycle of merging and splitting. This thrashing merge-split behavior is terrible news for index performance.</p>\n<blockquote>\n<p>If both pages are close to 50% full, a page split can occur soon after the pages are merged. If this merge-split behavior occurs frequently, it can have an adverse affect on performance. To avoid frequent merge-splits, you can lower the MERGE_THRESHOLD value so that InnoDB attempts page merges at a lower “page-full” percentage. Merging pages at a lower page-full percentage leaves more room in index pages and helps reduce merge-split behavior.</p>\n</blockquote>\n<p>What happens if you over-tune the <code>MERGE_THRESHOLD</code> knob for your workload?</p>\n<blockquote>\n<p>A MERGE_THRESHOLD setting that is too small could result in large data files due to an excessive amount of empty page space.</p>\n</blockquote>\n<p>This results in index bloat, which directly harms read efficiency. The same key space instead of being densely packed, is now spread over a larger number of sparse nodes, requiring more I/O for range scans, and takes up more buffer pool capacity to keep the index in memory.</p>\n<h3 id=\"do-nothing-strategy-in-postgresql\" tabindex=\"-1\">Do Nothing Strategy In PostgreSQL <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#do-nothing-strategy-in-postgresql\" aria-hidden=\"true\">#</a></h3>\n<p>In PostgreSQL deleting an index entry happens in two separate phases: a logical deletion followed by a physical deletion. The logical deletion creates a tombstone marker, and is lightweight. The physical deletion is more expensive, and happens in the background.</p>\n<p>When a node underflows, PostgreSQL does nothing to rectify the situation. The only time it attempts to reclaim space is when all the entries are removed from a leaf node and it becomes empty.</p>\n<blockquote>\n<p>We consider deleting an entire page from the btree only when it's become\ncompletely empty of items. (Merging partly-full pages would allow better\nspace reuse, but it seems impractical to move existing data items left or\nright to make this happen --- a scan moving in the opposite direction\nmight miss the items if so.)</p>\n</blockquote>\n<p>There is an exception to this rule. PostgreSQL will never delete the right-most child of a parent on any given level, even if it becomes empty. Removing the right-most node will have to be followed by transferring the key space used for navigation to the next or previous parent. Since we do not hold latches on those nodes yet, they will have to be freshly acquired. All of this is avoided by sticking to this rule, and it simplifies the implementation.</p>\n<blockquote>\n<p>To preserve consistency on the parent level, we cannot merge the key space\nof a page into its right sibling unless the right sibling is a child of\nthe same parent --- otherwise, the parent's key space assignment changes\ntoo, meaning we'd have to make bounding-key updates in its parent, and\nperhaps all the way up the tree. Since we can't possibly do that\natomically, we forbid this case.</p>\n</blockquote>\n<p>The deletion of a node is also separated into logical and physical phases. A logical deletion happens first which marks a tombstone. A physical deletion, which reclaims the space for reuse is only performed when this node is not visible to any active transactions.</p>\n<blockquote>\n<p>Recycling a page is decoupled from page deletion. A deleted page can only\nbe put in the FSM to be recycled once there is no possible scan or search\nthat has a reference to it; until then, it must stay in place with its\nsibling links undisturbed, as a tombstone that allows concurrent searches\nto detect and then recover from concurrent deletions (which are rather\nlike concurrent page splits to searchers).</p>\n</blockquote>\n<p><a href=\"https://github.com/postgres/postgres/blob/master/src/backend/access/nbtree/README\">Source</a>: <code>src/backend/access/nbtree/README</code></p>\n<h2 id=\"key-takeaways\" tabindex=\"-1\">Key Takeaways <a class=\"direct-link\" href=\"https://jacobsherin.com/posts/2025-08-16-bplustree-compare-borrow-merge/#key-takeaways\" aria-hidden=\"true\">#</a></h2>\n<p>Fixing a node underflow is presented as a binary choice between a merge-first or borrow-first approach for tree rebalancing at the data structure level. For a concurrent implementation, when a node underflow happens the pessimistic (slower) path is preferred for correctness and protecting the integrity of the B+Tree. For non-OLTP use cases, neither merge-first nor borrow-first is inherently better than the other.</p>\n<p>In MySQL the rebalancing is offline, and happens in the background. While in PostgreSQL, rebalancing is not undertaken for node underflows. The priority is higher concurrency by avoiding rebalancing. The trade-off in both systems is accumulating index bloat. The burden of managing index bloat now falls upon the operator.</p>\n<p>Two brilliant lessons we can learn from these OLTP systems to improve concurrency are: offline (asynchronous) rebalancing, and separating the deletion of entries, and nodes into logical and physical phases.</p>\n",
      "date_published": "2025-08-16T00:00:00Z"
    }
  ]
}
