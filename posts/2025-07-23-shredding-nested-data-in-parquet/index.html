<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Shredding Nested Data In Parquet</title>
    <meta name="description" content="jcsherin writes about programming">
    <meta name="generator" content="Eleventy v1.0.1">

    <link rel="stylesheet" href="/css/index.css">
    <link rel="stylesheet" href="/css/prism-base16-monokai.dark.css">
    <link rel="stylesheet" href="/css/prism-diff.css">
    <link rel="alternate" href="/feed/feed.xml" type="application/atom+xml" title="jcsherin">
    <link rel="alternate" href="/feed/feed.json" type="application/json" title="jcsherin">
  </head>
  <body>
    <div class="page-wrapper">
      <header>
        <h1 class="home"><a href="/">jcsherin</a></h1>
        <ul class="nav">
          <li class="nav-item"><a href="/">Writings</a></li>
          <li class="nav-item"><a href="/about/">About</a></li>
        </ul>
      </header>
      <h4 class="page-subtitle">Bridging Theory and Practice: Exploring Analytical Query Execution with Apache DataFusion, Parquet, and Apache Arrow</h4>

      <main class="tmpl-post">
        <h1>Shredding Nested Data In Parquet</h1>

<time datetime="2025-07-23">23 Jul 2025</time>


  <div class="draft-indicator">
    <p><strong>DRAFT</strong></p>
    <p>This is a draft preview. To publish, remove draft: true from the front matter.</p>
  </div>


<h2 id="shredding-nested-data-in-parquet" tabindex="-1">Shredding Nested Data in Parquet <a class="direct-link" href="#shredding-nested-data-in-parquet" aria-hidden="true">#</a></h2>
<p>OLAP database engines are able to execute aggregations, sorting and grouping over millions or billions of rows of data blazingly fast. The foundation for this extreme performance is a columnar storage format. Parquet is a columnar file format designed for efficient storage and fast retrieveal.</p>
<p>This performance is <strong>not</strong> limited to flat relational data which is trivial to map into a columnar format. It also works for nested data structures. But it requires some clever encoding techniques to store nested data structures in a columnar format and be able to reconstruct them back.</p>
<p>The performance of querying flat relational data is generally significantly better than querying nested data structures in OLTP database engines for transactional workloads.</p>
<p>It may feel counter-intuitive that in OLAP engines the difference between querying flat and nested data is often minimal.</p>
<p>The magic lies in the Dremel shredding technique adopted by Parquet for storing nested data. Dremel is the query execution engine in Google BigQuery. This novel techinque for improving analytical query performance over nested data was introduced by Dremel to the rest of the world.</p>
<p>Shredding is the term now commonly used in the context of the Parquet format and proprietary columnar formats of OLAP databases for the process of converting nested data into columnar representation.</p>
<p>The shredded data can be reassembled back to its original form. By design it is also possible to partially reconstruct the nested data which is generally applicable for analytical workloads. So during analysis you can write queries which only target a handful of paths in the nested data.</p>
<p>This post will cover the various challenges inherent in mapping nested data structures to a columnar storage format. We will try to uncover the ingenious design decisions which makes shredding work perfectly in every case.</p>
<p>Before we see how shredding nested data leads to efficient storage and retrieval, we need to first understand how columnar format affects query execution performance. But if you are already familiar with columnar formats, you can safely skip the next section.</p>
<h3 id="columnar-format" tabindex="-1">Columnar Format <a class="direct-link" href="#columnar-format" aria-hidden="true">#</a></h3>
<p>In a columnar format the values of a single column are stored together. The values are homogenous. They have the same datatype. So data-aware light-weight compression schemes like run-length encoding, dictionary encoding, delta encoding etc. can be applied to compact the data.</p>
<h4 id="data-aware-compression" tabindex="-1">Data-aware compression <a class="direct-link" href="#data-aware-compression" aria-hidden="true">#</a></h4>
<p>Consider a <code>timestamp</code> column which is in sorted order. It is stored as 64-bit integer in Parquet. Storing a million timestamp values alone will occupy 64 million bits or 8 million bytes (8 MB) of storage.</p>
<p>We can apply delta-encoding. The first timestamp (64-bits) is stored as reference. Then we store only the difference. Let us assume that the difference between timestamp values is small enough that it can be represented in 16-bits. If the unit of timestamp is milliseconds (ms), then 16-bits represents 65,536ms ~ 1 minute. So this will work if all the adjacent values are separated by less than a minute from each other.</p>
<p>With delta-encoding now it occupies only 16 million bits or 2 million bytes (2 MB) of storage. That is a 4x improvement in storage size over the uncompressed data.</p>
<h4 id="efficient-read-io" tabindex="-1">Efficient Read I/O <a class="direct-link" href="#efficient-read-io" aria-hidden="true">#</a></h4>
<p>In the SQL query if you specify the columns you want to read like: <code>SELECT column1, column2 * from t</code> because of columnar layout by design you only need to do disk I/O for reading exactly those columns: <code>column1</code> and <code>column2</code>. The other columns do not have to be scanned if they do not appear in the query. This improves I/O efficiency of queries and less data is read during query execution. This is another contributor to query execution speed.</p>
<h4 id="data-parallelism" tabindex="-1">Data Parallelism <a class="direct-link" href="#data-parallelism" aria-hidden="true">#</a></h4>
<p>If you execute an aggregation query: <code>SELECT SUM(column1) from t</code> it will scan all the values in <code>column1</code> from the Parquet file on disk. The implementation of sum will be looping over the values and accumulating the sum by adding one number after another until all the <code>column1</code> values are added up. The accumulated sum is returned as the query result.</p>
<p>Normally, the addition of two numbers in the CPU is a scalar instruction. But here the compiler can optimize this hot loop and convert the scalar sum into a vectorized sum instruction. In a vectorized sum instruction you can add more than two numbers in a single instruction.</p>
<p>If the CPU supports a 256-bit width register and we are adding together 32-bit integers. This register can hold eight 32-bit integers. The CPU can do 8 additions in parallel. To find the sum of 16 numbers you need 16 <code>ADD</code> operations. For large numbers vectorization will be dramatically more efficient in terms of the number of instructions executed.</p>
<h3 id="direct-storage-as-binary-blob" tabindex="-1">Direct Storage As Binary Blob <a class="direct-link" href="#direct-storage-as-binary-blob" aria-hidden="true">#</a></h3>
<p>The direct method is to stored the nested data (probably JSON format) values in a column as a binary blob. Since the physical storage type is <code>BINARY</code> (a byte array) we cannot apply any light-weight compression schemes on this column.</p>
<p>The JSON path expression is the commonly used syntax for identifying the columns (paths) in the nested data structure that we want to query. This expression <code>$.user.posts[:3].tags[0:]</code> returns all the tags from the first three posts of a user object. The binary blob has to be deserialized to access the underlying JSON data. Even though we are only interested in the <code>tags</code> array, all the data must be deserialized to get to it.</p>
<p>Shredding solves this problem by transparently representing the nested data in storage as column values. The user can therefore can continue to query the nested data by using the fluent interface which refers to the path structure without considering how its represented internally in columnar format.</p>
<h3 id="shredding-requires-data-type" tabindex="-1">Shredding Requires Data Type <a class="direct-link" href="#shredding-requires-data-type" aria-hidden="true">#</a></h3>
<p>Nested data is a tree data structure. A path in the tree maps to a column in storage. Similar to how column values in flat relational data is stored together, here values which have the same path are stored together.</p>
<p>In columnar format values of column are stored together because they share the same data type. So for shredding a tree path into column values, the data type of the tree path should be known.</p>
<p>The query performance and storage efficiencies in columnar format stems from storing homogeneous values which share a data type together in storage.</p>
<p>For shredding nested data into columnar format the schema should be defined. Shredding works only with strongly-typed data. If the types are unknown we can fallback to <code>BINARY</code> blob column storage forgoeing performance and storage efficiency.</p>
<h3 id="schema-and-data-model" tabindex="-1">Schema &amp; Data Model <a class="direct-link" href="#schema-and-data-model" aria-hidden="true">#</a></h3>
<p>The nested data model includes:</p>
<ul>
<li><code>OPTIONAL</code>: This field can appear zero or one time.</li>
<li><code>REPEATED</code>: This field represents a list or array which contains zero or more elements.</li>
<li><code>group</code>: This is a nested struct field with contains one or more other fields.</li>
<li><code>REPEATED group</code>: This is an array of struct elements.</li>
</ul>
<p>This is the schema definition for a nested <code>Contact</code>:</p>
<pre class="language-text"><code class="language-text">message contact {<br>  OPTIONAL BINARY name (STRING);<br>  OPTIONAL group phones (LIST) {<br>    REPEATED group list {<br>      OPTIONAL group item {<br>        OPTIONAL BINARY number (STRING);<br>        OPTIONAL BINARY phone_type (STRING);<br>      }<br>    }<br>  }<br>}</code></pre>
<p>You can read this: <code>OPTIONAL BINARY phone_type (STRING)</code> as a field which has the name <code>phone_type</code> with the logical data type being a UTF-8 string, and the physical representation being binary. The field value may not always be present.</p>
<p>Here are a few valid examples of nested data of the <code>Contact</code> schema:</p>
<pre class="language-text"><code class="language-text">{name: "Alice", phones: [<br>	{number: "555-1234", phone_type: "Home"},<br>	{number: "555-5678", phone_type: "Work"}]}<br>{name: "Bob"}<br>{name: "Charlie"}<br>{name: "Diana", phones: [<br>	{number: "555-9999", phone_type: "Work"}]}<br>{phones: [{number: null, phone_type: "Home"}]}</code></pre>
<h3 id="the-dremel-encoding" tabindex="-1">The Dremel Encoding <a class="direct-link" href="#the-dremel-encoding" aria-hidden="true">#</a></h3>
<p>In flat relational data storing the values together in columns suffice. It is not that simple with nested data where the structure of the nested data needs to be preserved.</p>
<p>The structure is metadata and it needs to be encoded and stored together with the shredded values. This is the fundamental principle of Dremel Encoding.</p>
<p>For each value shredded from nested data, the structure can be encoded using only two integer values. These two integers fully describe the structure and helps in reassembling the nested data back from its shredded form.</p>
<p>The two metadata values for describing the structure of nested data are: <strong>definition level</strong> and <strong>repetition level</strong>.</p>
<h4 id="definition-level" tabindex="-1">Definition Level <a class="direct-link" href="#definition-level" aria-hidden="true">#</a></h4>
<p>This metadata maintains a count of all the optional and repeated fields which are present in a path. Let us look at a breakdown for the path: <code>phones.list.item.number</code>.</p>
<table>
<thead>
<tr>
<th>field</th>
<th>multiplicity</th>
<th>definition level</th>
</tr>
</thead>
<tbody>
<tr>
<td>phones</td>
<td>OPTIONAL</td>
<td>1</td>
</tr>
<tr>
<td>list</td>
<td>REPEATED</td>
<td>2</td>
</tr>
<tr>
<td>item</td>
<td>OPTIONAL</td>
<td>3</td>
</tr>
<tr>
<td>number</td>
<td>OPTIONAL</td>
<td>4</td>
</tr>
</tbody>
</table>
<p>The definition level of a value shredded from this path can have a maximum value of 4.</p>
<table>
<thead>
<tr>
<th>state</th>
<th>def</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>NULL</td>
<td>0</td>
<td><code>phones</code> is not defined</td>
</tr>
<tr>
<td>[]</td>
<td>1</td>
<td><code>list</code> is empty</td>
</tr>
<tr>
<td>[NULL]</td>
<td>2</td>
<td><code>item</code> is not defined</td>
</tr>
<tr>
<td>[{number: NULL}]</td>
<td>3</td>
<td><code>number</code> is not defined</td>
</tr>
<tr>
<td>[{number: &quot;555-9999&quot;}]</td>
<td>4</td>
<td>all the fields are defined</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Note: In the SQL or DataFrame frontend the <code>list</code> and <code>item</code> fields need not be explicitly mentioned. This is a storage level concern. The user can directly use the expression <code>$.phones[*].number</code> to get all the phone numbers from the nested data.</p>
</blockquote>
<h4 id="repetition-level" tabindex="-1">Repetition Level <a class="direct-link" href="#repetition-level" aria-hidden="true">#</a></h4>
<p>This metadata deals with only repeated fields. In the shredded form all we have is all the values of a path stored together in a column. The repetition level is critical for identifying to which nested data, the exact list and index of the shredded value. It is the final piece in being able reassemble complex nested data which often contains multiple repeated fields in a path.</p>
<p>In the <code>Contact</code> schema there is only a single repeated field. The repetition level is computed only for paths which contains at least one repeated field. So it applies to these paths in <code>Contact</code>:</p>
<ul>
<li><code>phones.list.item.number</code> and,</li>
<li><code>phones.list.item.phone_type</code></li>
</ul>
<p>The max possible repetition level for both paths is 1.</p>
<h3 id="putting-it-all-together" tabindex="-1">Putting it all Together <a class="direct-link" href="#putting-it-all-together" aria-hidden="true">#</a></h3>
<p>This is a partial projection of <code>Contact</code> values shown earlier:</p>
<pre class="language-text"><code class="language-text">[0] { phones: [<br>		{number: "555-1234", phone_type: "Home"},<br>		{number: "555-5678", phone_type: "Work"}]}<br>	]}<br>[1] {}<br>[2] {}<br>[3] { phones: [<br>		{number: "555-9999", phone_type: "Work"}<br>	]}<br>[4] { phones: [<br>		{number: null, phone_type: "Home"}<br>	]}</code></pre>
<p>Let us now take a look at the shredded form for the <code>number</code> column.</p>
<table>
<thead>
<tr>
<th><code>phones.list.item.number</code></th>
<th>rep</th>
<th>def</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td>&quot;555-1234&quot;</td>
<td>0</td>
<td>4</td>
<td>first phone number in first value</td>
</tr>
<tr>
<td>&quot;555-5678&quot;</td>
<td>1</td>
<td>4</td>
<td>next phone number in first value</td>
</tr>
<tr>
<td>NULL</td>
<td>0</td>
<td>0</td>
<td><code>phones</code> field is not defined</td>
</tr>
<tr>
<td>NULL</td>
<td>0</td>
<td>0</td>
<td><code>phones</code> field is not defined</td>
</tr>
<tr>
<td>&quot;555-9999&quot;</td>
<td>0</td>
<td>4</td>
<td>first phone number in 4th value</td>
</tr>
<tr>
<td>NULL</td>
<td>0</td>
<td>3</td>
<td>first phone number is not defined in 5th value</td>
</tr>
</tbody>
</table>
<p>The first <code>Contact</code> contains two <code>number</code> items. The first item is identified by a repetition level of 0, and the remaining items have a repetition level of 1. The definition level is 4 which means all the fields are present for both values. This can be reassembled as following:</p>
<pre class="language-text"><code class="language-text">{ phones: [<br>	{ number: "555-1234"},  // rep=0; def=4;<br>	{ number: "555-5678"},  // rep=0; def=4;<br>]}</code></pre>
<p>The next two values are <code>NULL</code>, but this is never really physically stored. This is an optimisation which has a high impact when dealing with sparse nested data. Even though there is no actual <code>NULL</code> stored physically, it can be inferred from the definition level not being equal to 4. The definition level value tells us exactly where the path terminated, so we know how to recreate it. Since the definition level is zero in both cases, we can infer that <code>phones</code> field itself is not present in the nested data.</p>
<p>The next contact contains only a single item. We know this because there is no successor item with a repetition level of 1. The definition level is 4, so we know all the fields in the path are present. This is reassembled into:</p>
<pre class="language-text"><code class="language-text">{ phones: [{number: "555-999"}] }</code></pre>
<p>The final shredded value is also a <code>NULL</code>, but the definition level is 3. So we know that <code>phones.list.item</code> is present, but the final <code>number</code> field is not. So this is reassemble into:</p>
<pre class="language-text"><code class="language-text">{ phones: [{number: null}] }</code></pre>
<h3 id="storage-optimizations" tabindex="-1">Storage Optimizations <a class="direct-link" href="#storage-optimizations" aria-hidden="true">#</a></h3>
<p>If the nested dataset is extremely sparse, there are going to be a lot <code>NULL</code> values present in the values array. But this is not an issue because <code>NULL</code> values are never stored in physical storage. When reading back the data this can be inferred from the definition level values. If the definition level is less than the max definition level for that path, then it can only mean that the path terminated early and therefore the value can only be <code>NULL</code>. This works out really well for sparse datasets as we incur no additional costs in storage.</p>
<p>You would have noticed by now that the definition level and repetition level values are dependent on the depth of the tree for any given path. If the nested data has a max depth of 7, then the level values will not exceed 7. In binary 7 is <code>0b111</code> which requires only 3-bits to encode. So both the definition and repetition level values can be bit-packed instead of representing them as 32-bit or 64-bit integers which will take up 4 to 8 bytes of storage per metdata value.</p>
<p>If a list contains a large number of elements, the first item will have a repetition level which identifies the beginning of the list. And the remaining elements will have the same repetition level. So if there are 1001 elements in the list, we can use run-length encoding to compress it further: <code>(M, 1), (N, 1000)</code>, where <code>M</code> and <code>N</code> represents the repetition level values and their corresponding run lengths.</p>
<p>If a path does not contain any repeated fields, we do not have to store the repetition levels for that column. Similarly if a top-level field is a required field (meaning it cannot be <code>NULL</code>) then the definition and repetitionl levels is going to be zero for all values. Here too we do not need to store both repetition levels or definition levels. This is because the top-level required field does not have any nesting.</p>
<p>The optimizations are significant in improving storage efficiency and reducing the amount of I/O required to read the shredded columns back from storage. We can have good things like shredding without trading off too much in storage space because of definition and repetition levels metadata.</p>
<h3 id="querying-nested-data" tabindex="-1">Querying Nested Data <a class="direct-link" href="#querying-nested-data" aria-hidden="true">#</a></h3>
<p>So now we have the nested data in shredded form, let us see how to query it.</p>
<pre class="language-text"><code class="language-text">SELECT *<br>  FROM read_parquet("contacts.parquet");<br>┌─────────┬──────────────────────────────────────────────────────────────────────────────────────┐<br>│  name   │                                        phones                                        │<br>│ varchar │                     struct(number varchar, phone_type varchar)[]                     │<br>├─────────┼──────────────────────────────────────────────────────────────────────────────────────┤<br>│ Alice   │ [{'number': 555-1234, 'phone_type': Home}, {'number': 555-5678, 'phone_type': Work}] │<br>│ Bob     │ NULL                                                                                 │<br>│ Charlie │ []                                                                                   │<br>│ Diana   │ [{'number': 555-9999, 'phone_type': Work}]                                           │<br>│ NULL    │ [{'number': NULL, 'phone_type': Home}]                                               │<br>└─────────┴──────────────────────────────────────────────────────────────────────────────────────┘</code></pre>
<h4 id="flattening-nested-phones-list" tabindex="-1">Flattening Nested <code>phones</code> list <a class="direct-link" href="#flattening-nested-phones-list" aria-hidden="true">#</a></h4>
<p>The <code>UNNEST</code> function is useful here to unnest the <code>phones</code> list into one item per row. This yields a struct row item: <code>{'number': 555-1234, 'phone_type': Home}</code> which can be further unnested into its individual fields: <code>number</code> and <code>phone_type</code>.</p>
<p>The DuckDB SQL dialect supports <a href="https://duckdb.org/docs/stable/sql/query_syntax/unnest.html#recursive-unnest">recursive unnesting</a>.</p>
<pre class="language-text"><code class="language-text">SELECT<br>    name,<br>    unnest(phones, recursive := true)<br>FROM<br>    read_parquet('contacts.parquet');<br>┌─────────┬──────────┬────────────┐<br>│  name   │  number  │ phone_type │<br>│ varchar │ varchar  │  varchar   │<br>├─────────┼──────────┼────────────┤<br>│ Alice   │ 555-1234 │ Home       │<br>│ Alice   │ 555-5678 │ Work       │<br>│ Diana   │ 555-9999 │ Work       │<br>│ NULL    │ NULL     │ Home       │<br>└─────────┴──────────┴────────────┘</code></pre>
<h4 id="summarizing-phone-types" tabindex="-1">Summarizing Phone Types <a class="direct-link" href="#summarizing-phone-types" aria-hidden="true">#</a></h4>
<pre class="language-text"><code class="language-text">SELECT<br>  phone.phone_type AS phone_type,<br>  COUNT(*) AS total<br>FROM<br>  read_parquet('contacts.parquet'),<br>  UNNEST(phones) AS t(phone)<br>GROUP BY<br>  phone_type<br>ORDER BY<br>  total DESC;<br>┌────────────┬───────┐<br>│ phone_type │ total │<br>│  varchar   │ int64 │<br>├────────────┼───────┤<br>│ Home       │     2 │<br>│ Work       │     2 │<br>└────────────┴───────┘</code></pre>
<h4 id="summarizing-phones-per-user" tabindex="-1">Summarizing Phones Per User <a class="direct-link" href="#summarizing-phones-per-user" aria-hidden="true">#</a></h4>
<pre class="language-text"><code class="language-text">SELECT<br>  name,<br>  len(phones) AS phone_count<br>FROM<br>  read_parquet('~/Documents/contacts.parquet')<br>ORDER BY<br>  phone_count DESC NULLS FIRST;<br>┌─────────┬─────────────┐<br>│  name   │ phone_count │<br>│ varchar │    int64    │<br>├─────────┼─────────────┤<br>│ Bob     │        NULL │<br>│ Alice   │           2 │<br>│ Diana   │           1 │<br>│ NULL    │           1 │<br>│ Charlie │           0 │<br>└─────────┴─────────────┘</code></pre>
<h3 id="point-lookups-involve-scanning-and-decoding" tabindex="-1">Point Lookups Involve Scanning and Decoding <a class="direct-link" href="#point-lookups-involve-scanning-and-decoding" aria-hidden="true">#</a></h3>
<p>An example is if we want to find the 1000th <code>phone_number</code>. The shredding flattens the <code>phone_number</code> into contiguous block of all phone numbers from all contacts. We cannot directly jump to the offset 1000 because <code>NULL</code> values are omitted from physical storage. Therefore the logical offset will not match the physical position in the stored column values.</p>
<p>The definition levels will have to be decoded and scanned from the beginning to map the logical offset 1000 to the physical offset in storage.</p>
<p>Consider a variation of this simple point lookup query but we also make it dependent on the <code>name</code> column where we want to find the 3rd non-null number for <code>Troy</code>.</p>
<p>Here we have to first scan the repetition levels to identify the beginning of <code>phone_numbers</code> for <code>Troy</code>. Then use the definition levels in tandem to skip any null values to find the target. Here the lookup process involves scanning and decoding both definition and repetition levels because of the dependency.</p>
<p>We are forced into sequential scans and full decoding of levels metadata to compute the result.</p>
<h3 id="all-or-nothing:-selective-shredding" tabindex="-1">All or Nothing: Selective Shredding <a class="direct-link" href="#all-or-nothing:-selective-shredding" aria-hidden="true">#</a></h3>
<p>The alternatives are to store nested data as a binary blob and forgoe any of the native optimizations available in columnar formats. The other is to completely shred the nested data with a strongly-typed schema.</p>
<p>There is no in-between. You cannot choose to selectively shred only a fraction of the nested data and then store the rest as a binary blob. This is useful for semi-structured data like JSON where sometimes the same key may have different data types in the value.</p>
<p>This case is not supported in traditional shredding of nested data.</p>
<h3 id="conclusion" tabindex="-1">Conclusion <a class="direct-link" href="#conclusion" aria-hidden="true">#</a></h3>
<p>Nested data has structure which needs to be preserved during shredding. The structural metadata is critical to being able to reassemble the full nested value or a partial projection.</p>
<p>Shredding requires knowing the column data type. So it works only if a schema definition is provided for the nested data. The data model contains optional, repeated and group fields which makes it expressive enough to model any real-world nested data.</p>
<p>Even though a single schema can lead to many variations in tree shapes of nested data instances, they can all be encoded with precision and fidelity during shredding by adding the structural metadata - definition &amp; repetition levels. By interpreting the definition levels &amp; repetition levels it is possible to reassemble the full or partial projection as required by the query.</p>


      </main>

      <footer></footer>

      <!-- Current page: /posts/2025-07-23-shredding-nested-data-in-parquet/ -->
    </body>
  </div>
</html>
