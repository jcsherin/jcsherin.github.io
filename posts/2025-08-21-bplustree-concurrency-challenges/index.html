<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Practical Hurdles In Crab Latching Concurrency</title>
    <meta name="description" content="On database building blocks.">
    <meta name="generator" content="Eleventy v1.0.1">
    <link rel="stylesheet" href="/css/prism-okaidia.css">
    <link rel="stylesheet" href="/css/custom.css?v=1756471926167">
    <link rel="alternate" href="/feed/feed.xml" type="application/atom+xml" title="">
    <link rel="alternate" href="/feed/feed.json" type="application/json" title="">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inria+Serif:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap" rel="stylesheet">
    <script>document.documentElement.classList.remove("no-js");</script>
  </head>
  <body>
    <div class="page-wrapper">
      <header>
        <hgroup>
        <h3 class="home"><a href="/">Jacob&#39;s blog</a></h3>
        <p>On database building blocks.</p>
      </hgroup>
        <ul class="nav">
          <li class="nav-item"><a href="/">posts</a></li>
          <li class="nav-item"><a href="/about/">whoami</a></li>
        </ul>
      </header>

      <main class="tmpl-post">
        

<h1>Practical Hurdles In Crab Latching Concurrency</h1>

<time datetime="2025-08-21">21 Aug 2025</time>

<p>An implementation of the crab latching protocol enforces a strict top-down order for acquiring latches on a B+Tree node. This avoid deadlocks from ever occurring during concurrent operations. This is distinct from deadlock detection and resolution which is a runtime mechanism.</p>
<p>Deadlock avoidance is guaranteed by design through careful programming of critical sections in the code. Any mistakes here will result in deadlocks. Even worse, a data race which silently corrupts the index.</p>
<p>The main strength of a B+Tree index (compared to a hash index) is its unique capability to perform range scans. This is possible because all the entries are stored in key lexicographic order in the leaf nodes, and the leaf nodes themselves are connected to each other like a doubly-linked list. So scanning is efficient once you locate the starting leaf node. Scanning in ascending or descending key order is as simple as following the left or right sibling pointers.</p>
<p>This forwards or backwards movement during index scans violates the strict top-down ordering required for safety and correctness by the crab latching protocol.</p>
<p>A delete algorithm which implements a symmetrical tree rebalancing procedure requires acquiring an exclusive latch on either a left or right sibling for merging nodes. There is an equal chance of nodes merging left-right and right-left. This too violates the strict ordering requirement.</p>
<p>Therefore, an implementation has to come up with practical methods to avoid serial execution order and preserve concurrency. There is no formal verification of correctness via proof in these scenarios. We can improve our confidence in the implementation through engineering effort: code reviews, test suites, analyzers (ThreadSanitizer). Though the existence of data races cannot be ruled out, in practice this is sufficient for a robust and reliable implementation as evidenced by major OLTP systems.</p>
<nav class="toc" aria-labelledby="toc-heading">
  <h2 id="toc-heading">Table of Contents</h2>
  <ol>
    <li>
      <a href="#an-overview-of-crab-latching">An Overview Of Crab Latching</a>
      <ul>
        <li><a href="#how-do-deadlocks-happen">How Do Deadlocks Happen?</a></li>
        <li><a href="#how-are-deadlocks-prevented">How Are Deadlocks Prevented?</a></li>
        <li><a href="#efficient-fine-grained-crab-latching">Efficient Fine-Grained Crab Latching</a></li>
      </ul>
    </li>
    <li>
      <a href="#concurrent-index-scans">Concurrent Index Scans</a>
      <ul>
        <li><a href="#extension-for-concurrent-bi-directional-scans">Extension For Concurrent Bi-directional Scans</a></li>
        <li><a href="#deadlock:-lock-order-inversion">Deadlock: Lock Order Inversion</a></li>
      </ul>
    </li>
    <li><a href="#extension-for-symmetric-deletion">Extension For Symmetric Deletion</a></li>
    <li><a href="#concurrent-scans-can-miss-entries">Concurrent Scans Can Miss Entries</a></li>
  </ol>
</nav>
<h2 id="an-overview-of-crab-latching" tabindex="-1">An Overview Of Crab Latching <a class="direct-link" href="#an-overview-of-crab-latching" aria-hidden="true">#</a></h2>
<blockquote>
<p>Latches are held only during a critical section, that is, while a data structure is read or updated. Deadlocks are avoided by appropriate coding disciplines, for example, requesting multiple latches in carefully designed sequences. Deadlock resolution requires a facility to rollback prior actions, whereas deadlock avoidance does not. Thus, deadlock avoidance is more appropriate for latches, which are designed for minimal overhead
and maximal performance and scalability. Latch acquisition and release may
require tens of instructions only, usually with no additional cache faults since a latch can be embedded in the data structure it protects.</p>
<p>Goetz Graefe, &quot;A Survey of B-Tree Locking Techniques&quot; (2010)</p>
</blockquote>
<h3 id="how-do-deadlocks-happen" tabindex="-1">How Do Deadlocks Happen? <a class="direct-link" href="#how-do-deadlocks-happen" aria-hidden="true">#</a></h3>
<p>(<code>Thread 1</code>) Holds an exclusive (write) latch on <code>Node P</code>. It now wants to acquire an exclusive latch on it's child <code>Node C</code> for inserting an element.</p>
<p>(<code>Thread 2</code>) Already holds an exclusive latch on <code>Node C</code>. It is waiting to acquire an exclusive latch on it's parent <code>Node P</code>, so that the pivot key can be updated.</p>
<p>This creates a deadlock, where neither threads can make any progress. This could have been prevented if a strict ordering of the direction in which latches are acquired existed. A top-down ordering is better because all traversals begin at the root node to reach a leaf node.</p>
<h3 id="how-are-deadlocks-prevented" tabindex="-1">How Are Deadlocks Prevented? <a class="direct-link" href="#how-are-deadlocks-prevented" aria-hidden="true">#</a></h3>
<p>The ordering requirement implies that only a parent node can acquire an exclusive latch on a child node. The implementation of <code>Thread 2</code> becomes an invalid state and should not be possible. So instead the exclusive latch on <code>Node P</code> is never released when traversing down to the child <code>Node C</code>. Since only one writer can hold the exclusive (write) latch at a time, this will not create a deadlock with <code>Thread 1</code>. The first thread to acquire the exclusive latch on <code>Node P</code>, will block the second thread.</p>
<p>Even though latches are light-weight and held only for a short duration of time, it is not a good idea to hold latches which are strictly not necessary. It will create contention in hot paths which is bad news for throughput. This is where the crab latching protocol shines with its efficiency.</p>
<h3 id="efficient-fine-grained-crab-latching" tabindex="-1">Efficient Fine-Grained Crab Latching <a class="direct-link" href="#efficient-fine-grained-crab-latching" aria-hidden="true">#</a></h3>
<p>In crab latching, a child node is considered &quot;unsafe&quot; if the current operation will cause it to either split (overflow) or merge (underflow). An &quot;unsafe&quot; node may also end up modifying it's parent like <code>Thread 2</code>. So exclusive latches are held for the entire path segment, which contains &quot;unsafe&quot; nodes.</p>
<p>But we know that a node split or merge is going to be rare. More often an insert or delete will be local to a leaf node and does not have cascading changes which recurse back to the root node. Such nodes are considered to be &quot;safe&quot;</p>
<p>In the common scenario, when crab latching sees that a child node is &quot;safe&quot;, it first acquires a shared (read-only) latch on the child node and then release it's shared (read-only) latch on the parent. Hence the &quot;crab latching&quot; terminology. A shared latch does not block other threads. An exclusive latch is only acquired on the leaf node at the time of an insertion or deletion.</p>
<p>This fine-grained latching is efficient and allows other concurrent readers and only makes writers to wait, improving overall throughput. This is the optimistic approach which assumes will happen in the general case. We fallback to the pessimistic approach only if leaf node will underflow or overflow after an operation.</p>
<h2 id="concurrent-index-scans" tabindex="-1">Concurrent Index Scans <a class="direct-link" href="#concurrent-index-scans" aria-hidden="true">#</a></h2>
<p>The fundamental problem is that the concurrency models do not take into consideration B+Tree iterators. At the leaf node, traversing to a sibling uses the bi-directional links between leaf nodes. An ascending scan moves from left-right, while a descending scan moves from right-left. This conflicts with the safety property for avoiding deadlocks that traversals have a strictly enforced direction. Following the protocol exactly means the implementation can provide only one type of scan, either forward (ascending) or reverse (descending), but never both together.</p>
<pre class="language-cpp"><code class="language-cpp"><span class="token comment">// A forward index scan</span><br><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">auto</span> iter <span class="token operator">=</span> index<span class="token punctuation">.</span><span class="token function">Begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> iter <span class="token operator">!=</span> index<span class="token punctuation">.</span><span class="token function">End</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">++</span>iter<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>  <span class="token keyword">int</span> key <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">*</span>iter<span class="token punctuation">)</span><span class="token punctuation">.</span>first<span class="token punctuation">;</span><br>  <span class="token keyword">int</span> value <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">*</span>iter<span class="token punctuation">)</span><span class="token punctuation">.</span>second<span class="token punctuation">;</span><br><span class="token punctuation">}</span><br><br><span class="token comment">// A reverse index scan</span><br><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">auto</span> iter <span class="token operator">=</span> index<span class="token punctuation">.</span><span class="token function">RBegin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> iter <span class="token operator">!=</span> index<span class="token punctuation">.</span><span class="token function">REnd</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token operator">--</span>iter<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>  <span class="token keyword">int</span> key <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">*</span>iter<span class="token punctuation">)</span><span class="token punctuation">.</span>first<span class="token punctuation">;</span><br>  <span class="token keyword">int</span> value <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">*</span>iter<span class="token punctuation">)</span><span class="token punctuation">.</span>second<span class="token punctuation">;</span><br><span class="token punctuation">}</span><br><br><span class="token comment">/**<br> * index.Begin()  : first element<br> * index.End()    : one-past-the-last element<br> * index.RBegin() : last element<br> * index.REnd()   : one-past-the-first element<br> */</span></code></pre>
<h3 id="extension-for-concurrent-bi-directional-scans" tabindex="-1">Extension For Concurrent Bi-directional Scans <a class="direct-link" href="#extension-for-concurrent-bi-directional-scans" aria-hidden="true">#</a></h3>
<p>A shared (read-only) or exclusive (write) latch blocks execution until the latch is acquired. For scans which are sideways traversals, we do not want to limit the traversal to any one direction. A blocking latch will create deadlocks if two concurrent scans proceed in opposite directions.</p>
<p>Therefore we need to use a non-blocking latch to prevent blocking and avoid deadlocks. A non-blocking latch will try to acquire a latch, and will return immediately.</p>
<pre class="language-cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;shared_mutex></span></span><br><br><span class="token keyword">class</span> <span class="token class-name">SharedLatch</span> <span class="token punctuation">{</span><br>  <span class="token comment">// Blocking</span><br>  <span class="token comment">//</span><br>  <span class="token comment">// If another thread holds the latch, execution will block</span><br>  <span class="token comment">// until the latch is acquired.</span><br>  <span class="token comment">//</span><br>  <span class="token comment">// Used in insert, delete &amp; search index operations</span><br>  <span class="token keyword">void</span> <span class="token function">LockShared</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>      latch_<span class="token punctuation">.</span><span class="token function">lock_shared</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>  <span class="token punctuation">}</span><br><br>  <span class="token comment">// Non-blocking</span><br>  <span class="token comment">//</span><br>  <span class="token comment">// Tries to acquire a latch. If successful returns `true`,</span><br>  <span class="token comment">// otherwise returns `false`.</span><br>  <span class="token comment">//</span><br>  <span class="token comment">// Used in ascending &amp; descending index scans</span><br>  <span class="token keyword">bool</span> <span class="token function">TryLockShared</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    <span class="token keyword">return</span> latch_<span class="token punctuation">.</span><span class="token function">try_lock_shared</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>  <span class="token punctuation">}</span><br><br>  <span class="token keyword">private</span><span class="token operator">:</span><br>    <span class="token comment">// A wrapper around std::shared_mutex</span><br>    std<span class="token double-colon punctuation">::</span>shared_mutex latch_<span class="token punctuation">;</span><br><span class="token punctuation">}</span></code></pre>
<p>Using <code>TryLockShared()</code> forces us rethink how a scan implementation should work if latch acquisition fails. In contrast, the concurrent insert, delete and search implementations are always expected to return a result matching its output type in the signature.</p>
<pre class="language-cpp"><code class="language-cpp"><span class="token comment">// Returns `std::nullopt` if the key is not found in the index</span><br>std<span class="token double-colon punctuation">::</span>optional<span class="token operator">&lt;</span>KeyType<span class="token operator">></span> <span class="token function">MaybeGet</span><span class="token punctuation">(</span>KeyType key<span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// Returns `false` if key is a duplicate.</span><br><span class="token comment">//</span><br><span class="token comment">// Note: This prevents overwriting an existing key. The handling of</span><br><span class="token comment">// duplicate keys is an implementation specific detail.</span><br><span class="token keyword">bool</span> <span class="token function">Insert</span><span class="token punctuation">(</span><span class="token keyword">const</span> KeyValuePair element<span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// Returns `false` if the key does not exist.</span><br><span class="token keyword">bool</span> <span class="token function">Delete</span><span class="token punctuation">(</span><span class="token keyword">const</span> KeyType key_to_remove<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
<p>We can introduce a failure mode, where if latch acquisition fails during a scan we set its internal state to <code>RETRY</code>.</p>
<pre class="language-cpp"><code class="language-cpp"><span class="token keyword">enum</span> <span class="token class-name">IteratorState</span> <span class="token punctuation">{</span><br>    VALID<span class="token punctuation">,</span> INVALID<span class="token punctuation">,</span> END<span class="token punctuation">,</span> REND<span class="token punctuation">,</span> RETRY<br><span class="token punctuation">}</span><span class="token punctuation">;</span></code></pre>
<p>The implementation for forward scan which uses a non-blocking latch and retriable iterator looks like this:</p>
<pre class="language-cpp"><code class="language-cpp"><span class="token comment">// Move forward one element at a time. If latch acquisition</span><br><span class="token comment">// failed, then set internal state to `RETRY`.</span><br><span class="token keyword">void</span> <span class="token keyword">operator</span><span class="token operator">++</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>  <span class="token comment">// ...</span><br><br>  <span class="token comment">// The `TrySharedLock()` is a non-blocking read-only latch</span><br>  <span class="token comment">// which returns `true` or `false` immediately.</span><br>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token punctuation">(</span>current_node_<span class="token operator">-></span><span class="token function">TrySharedLock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    previous_node<span class="token operator">-></span><span class="token function">ReleaseNodeSharedLatch</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br>    <span class="token comment">// Invalidates the iterator.</span><br>    <span class="token comment">// Sets internal state to `RETRY`.</span><br>    <span class="token function">SetRetryIterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    <span class="token keyword">return</span><span class="token punctuation">;</span><br>  <span class="token punctuation">}</span><br><br>  <span class="token comment">// ...</span><br><br><span class="token punctuation">}</span><br><br><br><span class="token keyword">void</span> <span class="token function">SetRetryIterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>  <span class="token comment">// Resets internal state</span><br>  current_node_ <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span><br>  current_element_ <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span><br><br>  state_ <span class="token operator">=</span> RETRY<span class="token punctuation">;</span><br><span class="token punctuation">}</span></code></pre>
<p>We have a working bi-directional iterator implementation which will avoid deadlocks, but it is not yet free from data races.</p>
<h3 id="deadlock:-lock-order-inversion" tabindex="-1">Deadlock: Lock Order Inversion <a class="direct-link" href="#deadlock:-lock-order-inversion" aria-hidden="true">#</a></h3>
<p>The current API introduces a deadlock if the user initializes two iterators within the same scope, within the same thread.</p>
<pre class="language-cpp"><code class="language-cpp"><span class="token keyword">auto</span> iter_forward <span class="token operator">=</span> index<span class="token punctuation">.</span><span class="token function">Begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// The second iterator creates a lock order inversion.</span><br><span class="token keyword">auto</span> iter_reverse <span class="token operator">=</span> index<span class="token punctuation">.</span><span class="token function">RBegin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
<p>A deadlock is prevented by enforcing a strict direction for latching. Any concurrent operation must therefore acquire a latch on an ancestor node before acquiring a latch on a descendant node (top-down traversal).</p>
<p>The iterator here holds a shared (read-only) latch on the leaf it points to. If that iterator remains alive while another operation begins a new top-down traversal from the root, we can get a deadlock.</p>
<p>(<code>Thread 1</code>): Creates a forward iterator, which holds a shared latch on a leaf node.</p>
<p>(<code>Thread 2</code>): Begins an insert in the pessimistic path acquiring an exclusive latch beginning at the root node all the way down to the parent of the same leaf node.</p>
<p>(<code>Thread 2</code>): Now attempts to acquire an exclusive latch on the leaf node but it blocks, waiting for the forward iterator to complete and release its shared latch on the leaf node.</p>
<p>(<code>Thread 1</code>): Creates a second reverse iterator, which is now blocking to acquire a shared lock on the root. It is waiting for the insert operation to release the exclusive latch.</p>
<p>This creates a deadlock, even though in implementation we enforced a strict ordering. We can ensure that this does not happen by ensuring that iterator lifetimes do not intersect each other, by introducing a local scope.</p>
<p>Most importantly, the shared latch is released at the end of the scope and therefore it also enforces a global ordering for latch acquisition and will not result in a deadlock like described above.</p>
<pre class="language-cpp"><code class="language-cpp"><span class="token punctuation">{</span><br>  <span class="token keyword">auto</span> iter_forward <span class="token operator">=</span> index<span class="token punctuation">.</span><span class="token function">Begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token punctuation">}</span><br><br><span class="token comment">// The lifetime of the first iterator ends before this</span><br><span class="token comment">// scope starts. This guarantees that the shared latch</span><br><span class="token comment">// on the leaf node is released before we start traversal</span><br><span class="token comment">// from the root node.</span><br><span class="token punctuation">{</span><br>  <span class="token keyword">auto</span> iter_reverse <span class="token operator">=</span> index<span class="token punctuation">.</span><span class="token function">RBegin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token punctuation">}</span></code></pre>
<p>To ensure safety, the latching protocol has to be enforced for concurrent operations within the same thread. Unfortunately, our non-blocking, retriable concurrent scan iterators has introduced an API which is easy for the user to incorrectly implement, and must come with warnings.</p>
<p>The pattern of creating two iterators in the same scope creates a lock-order-inversion within a single thread. While this does not create a deadlock by itself, because of shared latches, it creates the precondition for a deadlock with any concurrent operation which falls down the pessimistic concurrency path.</p>
<h2 id="extension-for-symmetric-deletion" tabindex="-1">Extension For Symmetric Deletion <a class="direct-link" href="#extension-for-symmetric-deletion" aria-hidden="true">#</a></h2>
<p>A symmetric delete algorithm will proceed with a tree rebalancing operation after an underflow by attempting to merge with either the left sibling, and if that doesn't work with the right sibling at any level in the B+Tree. This violates our strict ordering principle for acquiring latches, because a merge can proceed in either direction.</p>
<p>(<code>Thread 1</code>): operating on Node B, needs to merge with its previous sibling, Node A. It holds an exclusive latch on B and tries to acquire an exclusive latch on A. (left to right)</p>
<p>(<code>Thread 2</code>): operating on Node A, needs to merge with its next sibling, Node B. It holds an exclusive latch on A and tries to acquire an exclusive latch on B. (right to left)</p>
<p>The creates a deadlock.</p>
<p>The fix is to enforce a strict one-way (say left-to-right) latch acquisition order. This is a delicate operation. Before locking the previous sibling A, the exclusive lock on the current node is released. The locks are reacquired in the correct order. First on the previous sibling, then on the current node.</p>
<pre class="language-cpp"><code class="language-cpp"><br>  <span class="token keyword">auto</span> maybe_previous <span class="token operator">=</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span>InnerNode <span class="token operator">*</span><span class="token operator">></span></span></span><span class="token punctuation">(</span>parent<span class="token punctuation">)</span><span class="token operator">-></span><span class="token function">MaybePreviousWithSeparator</span><span class="token punctuation">(</span>key_to_remove<span class="token punctuation">)</span><span class="token punctuation">;</span><br><br>  <span class="token keyword">if</span> <span class="token punctuation">(</span>maybe_previous<span class="token punctuation">.</span><span class="token function">has_value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br><br>    <span class="token comment">/* ... */</span><br><br>    <span class="token comment">// Enforcing a strict left-to-right (one-way) ordering</span><br>    right<span class="token operator">-></span><span class="token function">ReleaseNodeExclusiveLatch</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    left<span class="token operator">-></span><span class="token function">GetNodeExclusiveLatch</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>    right<span class="token operator">-></span><span class="token function">GetNodeExclusiveLatch</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br>    <span class="token comment">/* ... */</span><br>  <span class="token punctuation">}</span></code></pre>
<h2 id="concurrent-scans-can-miss-entries" tabindex="-1">Concurrent Scans Can Miss Entries <a class="direct-link" href="#concurrent-scans-can-miss-entries" aria-hidden="true">#</a></h2>
<p>Earlier in the case of concurrent scans we saw how local reasoning of strict ordering is not sufficient, because of the extension. A global strict ordering has to be enforced to prevent unintended deadlocks from interaction of scans with other concurrent operations.</p>
<p>Now let us look at a scenario where both the extensions can interact in a manner which violates strict ordering and introduces lock order inversion bugs in subtle ways.</p>
<p>(<code>Thread 1</code>): A forward scan iterator has completed scanning entries in Node A, and is next going to process it's right sibling Node B.</p>
<p>(<code>Thread 2</code>): A delete operation has taken the pessimistic path, because Node B is going to underflow after removing this entry. So it decides to merge with left sibling Node A. It already holds an exclusive latch on Node B and has to acquire an exclusive latch on Node B.</p>
<p>If the forward scan operator releases its shared latch on Node A, before it acquires a shared latch on Node B, the following sequence of events can happen with the right timing of events.</p>
<p>(<code>Thread 1</code>): Releases latch on Node A before acquiring a latch on Node B.</p>
<p>(<code>Thread 2</code>): Release exclusive latch on Node B. Acquires exclusive latch on Node A. Acquires the exclusive latch back on Node B.</p>
<p>(<code>Thread 1</code>): Is blocked by the exclusive latch held on Node B, by the delete operation in <code>Thread 2</code>.</p>
<p>(<code>Thread 2</code>): Merges Node A and B together, and modifies the right sibling pointer to Node C.</p>
<p>(<code>Thread 1</code>): Finally acquires a latch on Node C which is the new right sibling on Node A, not realizing it missed node B completely.</p>
<p>If latches acquisition is not crafted carefully in the iterator code, the following situation creates a race condition which is very hard to even detect, or reproduce.</p>
<p>The fix here is to correctly implement crab latching in the iterator code. A shared lock should not be released before <code>TrySharedLock()</code> is attempted on the sibling node. Doing so results in race conditions which are impossible to track down. This requires careful programming discipline.</p>

<hr>
<ul><li>Previous: <a href="/posts/2025-08-18-bplustree-struct-hack/">Cache-Friendly B+Tree Nodes With Dynamic Fanout</a></li>
</ul>

      </main>

      <footer></footer>

      <!-- Current page: /posts/2025-08-21-bplustree-concurrency-challenges/ -->
    </body>
  </div>
</html>
